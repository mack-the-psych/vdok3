{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import filecmp\n",
    "import difflib\n",
    "\n",
    "def file_cmp_diff_ratio(file1, file2):\n",
    "    print('Match test against:', file2, filecmp.cmp(file1, file2))\n",
    "\n",
    "    with open(file1,'r') as f:\n",
    "        str1 = f.readlines()\n",
    "\n",
    "    with open(file2,'r') as f:\n",
    "        str2 = f.readlines()\n",
    "\n",
    "    print('Str match ratio:', difflib.SequenceMatcher(None, str1, str2).ratio())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.16416603e+01 2.09187341e+00 1.87038006e+00 1.47345400e+00\n",
      " 1.39995353e+00 1.29821553e+00 1.20264899e+00 1.00323338e+00\n",
      " 8.02698031e-01 7.18430159e-01 6.71986110e-01 5.56788913e-01\n",
      " 5.36881631e-01 4.50204640e-01 3.25621142e-01 2.70044444e-01\n",
      " 2.23729028e-01 1.60979364e-01 1.29614493e-01 9.46431199e-02\n",
      " 4.86865443e-02 1.48092665e-02 5.49516970e-03 4.19008616e-03\n",
      " 2.09545370e-03 1.06192762e-03 6.21316148e-04]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%run ../train/pca.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match test against: ./orig_data/PCA-Def-PRE.csv True\n",
      "Str match ratio: 1.0\n"
     ]
    }
   ],
   "source": [
    "test_file = 'PCA-Def-PRE.csv'\n",
    "file_cmp_diff_ratio('../data/' + test_file, './orig_data/' + test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "RANDOM SET:  0\n",
      "Concat Value Len: 3127\n",
      "C: 0.0001\n",
      "score(mean): 0.8484312599681021\n",
      "C: 0.001\n",
      "score(mean): 0.9133392025518342\n",
      "C: 0.01\n",
      "score(mean): 0.9203710366826157\n",
      "C: 0.1\n",
      "score(mean): 0.9232469537480064\n",
      "C: 1.0\n",
      "score(mean): 0.9213300159489632\n",
      "C: 10.0\n",
      "score(mean): 0.9139771610845294\n",
      "C: 100.0\n",
      "score(mean): 0.8851975757575758\n",
      "C: 1000.0\n",
      "score(mean): 0.890308389154705\n",
      "C: 10000.0\n",
      "score(mean): 0.8967043062200958\n",
      "C: 100000.0\n",
      "score(mean): 0.9015032854864433\n",
      "C: 1000000.0\n",
      "score(mean): 0.8982940988835726\n",
      "C: 10000000.0\n",
      "score(mean): 0.8848724720893142\n",
      "C: 100000000.0\n",
      "score(mean): 0.8941534928229664\n",
      "C: 1000000000.0\n",
      "score(mean): 0.8944663476874004\n",
      "C: 10000000000.0\n",
      "score(mean): 0.8909504306220095\n",
      "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "Recall                      0.9194\n",
      "Precision                   0.9135\n",
      "F1                          0.9123\n",
      "Kappa                       0.6540\n",
      "Quadratic Weighted Kappa    0.7145\n",
      "dtype: float64\n",
      "Confusion Matrix:\n",
      "     0   1   2\n",
      "0  878   4   4\n",
      "1   38  57  16\n",
      "2   13   9  23\n",
      "----------------\n",
      "RANDOM SET:  1\n",
      "Concat Value Len: 3127\n",
      "C: 0.0001\n",
      "score(mean): 0.8484213950815732\n",
      "C: 0.001\n",
      "score(mean): 0.9072596072847057\n",
      "C: 0.01\n",
      "score(mean): 0.9162145150774341\n",
      "C: 0.1\n",
      "score(mean): 0.919732481786472\n",
      "C: 1.0\n",
      "score(mean): 0.9178129913380155\n",
      "C: 10.0\n",
      "score(mean): 0.9053314315929013\n",
      "C: 100.0\n",
      "score(mean): 0.8934996039765402\n",
      "C: 1000.0\n",
      "score(mean): 0.8868035658887383\n",
      "C: 10000.0\n",
      "score(mean): 0.8864707960802158\n",
      "C: 100000.0\n",
      "score(mean): 0.8800753738442488\n",
      "C: 1000000.0\n",
      "score(mean): 0.8896626514632164\n",
      "C: 10000000.0\n",
      "score(mean): 0.8887123508944393\n",
      "C: 100000000.0\n",
      "score(mean): 0.8890405298316951\n",
      "C: 1000000000.0\n",
      "score(mean): 0.879785032315367\n",
      "C: 10000000000.0\n",
      "score(mean): 0.8925477632921419\n",
      "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "Recall                      0.9184\n",
      "Precision                   0.9139\n",
      "F1                          0.9134\n",
      "Kappa                       0.6325\n",
      "Quadratic Weighted Kappa    0.6991\n",
      "dtype: float64\n",
      "Confusion Matrix:\n",
      "     0   1   2\n",
      "0  882  17   2\n",
      "1   29  49   5\n",
      "2   17  15  26\n",
      "----------------\n",
      "RANDOM SET:  2\n",
      "Concat Value Len: 3127\n",
      "C: 0.0001\n",
      "score(mean): 0.8375522807017542\n",
      "C: 0.001\n",
      "score(mean): 0.9066192025518343\n",
      "C: 0.01\n",
      "score(mean): 0.9158951196172248\n",
      "C: 0.1\n",
      "score(mean): 0.9165371610845294\n",
      "C: 1.0\n",
      "score(mean): 0.9162171610845296\n",
      "C: 10.0\n",
      "score(mean): 0.9091843062200958\n",
      "C: 100.0\n",
      "score(mean): 0.876254928229665\n",
      "C: 1000.0\n",
      "score(mean): 0.8816806379585327\n",
      "C: 10000.0\n",
      "score(mean): 0.8870971610845295\n",
      "C: 100000.0\n",
      "score(mean): 0.8842324720893142\n",
      "C: 1000000.0\n",
      "score(mean): 0.8832877830940988\n",
      "C: 10000000.0\n",
      "score(mean): 0.8765565550239234\n",
      "C: 100000000.0\n",
      "score(mean): 0.8915863476874003\n",
      "C: 1000000000.0\n",
      "score(mean): 0.885521658692185\n",
      "C: 10000000000.0\n",
      "score(mean): 0.8631114513556619\n",
      "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "Recall                      0.9299\n",
      "Precision                   0.9247\n",
      "F1                          0.9267\n",
      "Kappa                       0.6546\n",
      "Quadratic Weighted Kappa    0.7294\n",
      "dtype: float64\n",
      "Confusion Matrix:\n",
      "     0   1   2\n",
      "0  898  14   5\n",
      "1   29  46   6\n",
      "2    9  10  25\n",
      "----------------\n",
      "RANDOM SET:  3\n",
      "Concat Value Len: 3126\n",
      "C: 0.0001\n",
      "score(mean): 0.8432560711067421\n",
      "C: 0.001\n",
      "score(mean): 0.9078659687064798\n",
      "C: 0.01\n",
      "score(mean): 0.9161885393626606\n",
      "C: 0.1\n",
      "score(mean): 0.9200285442778734\n",
      "C: 1.0\n",
      "score(mean): 0.9193885459162775\n",
      "C: 10.0\n",
      "score(mean): 0.9107500729089866\n",
      "C: 100.0\n",
      "score(mean): 0.8835669140657\n",
      "C: 1000.0\n",
      "score(mean): 0.8784325747521914\n",
      "C: 10000.0\n",
      "score(mean): 0.8886894961907101\n",
      "C: 100000.0\n",
      "score(mean): 0.8941284623576635\n",
      "C: 1000000.0\n",
      "score(mean): 0.8845141214057508\n",
      "C: 10000000.0\n",
      "score(mean): 0.8663042893421806\n",
      "C: 100000000.0\n",
      "score(mean): 0.8803602539526502\n",
      "C: 1000000000.0\n",
      "score(mean): 0.8995561907102483\n",
      "C: 10000000000.0\n",
      "score(mean): 0.8829320340788073\n",
      "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "Recall                      0.9223\n",
      "Precision                   0.9143\n",
      "F1                          0.9161\n",
      "Kappa                       0.6514\n",
      "Quadratic Weighted Kappa    0.6835\n",
      "dtype: float64\n",
      "Confusion Matrix:\n",
      "     0   1   2\n",
      "0  884   9   5\n",
      "1   29  52   6\n",
      "2   19  13  26\n",
      "----------------\n",
      "ALL DATA:\n",
      "Recall                      0.9225\n",
      "Precision                   0.9146\n",
      "F1                          0.9170\n",
      "Kappa                       0.6480\n",
      "Quadratic Weighted Kappa    0.7059\n",
      "dtype: float64\n",
      "Confusion Matrix:\n",
      "      0    1    2\n",
      "0  3542   44   16\n",
      "1   125  204   33\n",
      "2    58   47  100\n",
      "Wall time: 6min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%run ../train/svm_classify.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match test against: ./orig_data/SVM-Classified-Prediction-Def-PRE-All.csv True\n",
      "Str match ratio: 1.0\n"
     ]
    }
   ],
   "source": [
    "test_file = 'SVM-Classified-Prediction-Def-PRE-All.csv'\n",
    "file_cmp_diff_ratio('../data/' + test_file, './orig_data/' + test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "RANDOM SET:  0\n",
      "Concat Value Len: 3127\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:189: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Step: 10, Loss: 3350.001465, Accuracy(train): 0.845539\n",
      "Step: 20, Loss: 3269.124512, Accuracy(train): 0.845539\n",
      "Step: 30, Loss: 3192.876709, Accuracy(train): 0.845859\n",
      "Step: 40, Loss: 3121.161377, Accuracy(train): 0.846178\n",
      "Step: 50, Loss: 3053.723389, Accuracy(train): 0.845859\n",
      "Step: 60, Loss: 2990.264160, Accuracy(train): 0.845859\n",
      "Step: 70, Loss: 2930.510986, Accuracy(train): 0.844579\n",
      "Step: 80, Loss: 2874.204590, Accuracy(train): 0.842661\n",
      "Step: 90, Loss: 2821.098145, Accuracy(train): 0.840422\n",
      "Step: 100, Loss: 2770.957520, Accuracy(train): 0.840102\n",
      "Step: 110, Loss: 2723.571289, Accuracy(train): 0.839463\n",
      "Step: 120, Loss: 2678.737793, Accuracy(train): 0.840102\n",
      "Step: 130, Loss: 2636.277100, Accuracy(train): 0.840102\n",
      "Step: 140, Loss: 2596.021973, Accuracy(train): 0.840102\n",
      "Step: 150, Loss: 2557.812744, Accuracy(train): 0.840102\n",
      "Step: 160, Loss: 2521.510498, Accuracy(train): 0.840102\n",
      "Step: 170, Loss: 2486.973145, Accuracy(train): 0.840422\n",
      "Step: 180, Loss: 2454.084473, Accuracy(train): 0.840742\n",
      "Step: 190, Loss: 2422.716553, Accuracy(train): 0.841381\n",
      "Step: 200, Loss: 2392.763428, Accuracy(train): 0.842021\n",
      "Step: 210, Loss: 2364.127441, Accuracy(train): 0.842341\n",
      "Step: 220, Loss: 2336.707031, Accuracy(train): 0.842661\n",
      "Step: 230, Loss: 2310.414795, Accuracy(train): 0.842661\n",
      "Step: 240, Loss: 2285.167236, Accuracy(train): 0.842661\n",
      "Step: 250, Loss: 2260.883545, Accuracy(train): 0.842661\n",
      "Step: 260, Loss: 2237.493896, Accuracy(train): 0.842341\n",
      "Step: 270, Loss: 2214.929199, Accuracy(train): 0.842661\n",
      "Step: 280, Loss: 2193.121094, Accuracy(train): 0.842661\n",
      "Step: 290, Loss: 2172.020752, Accuracy(train): 0.843300\n",
      "Step: 300, Loss: 2151.563232, Accuracy(train): 0.843300\n",
      "[[1.64383211e-04 5.02860040e-05 5.20901824e-05]\n",
      " [4.01224655e-05 2.19033366e-04 1.90550585e-04]\n",
      " [3.16146415e-05 2.81030369e-04 2.38056560e-04]\n",
      " ...\n",
      " [1.71478864e-04 4.81246068e-05 5.01527812e-05]\n",
      " [1.73437621e-04 4.75629188e-05 4.96644591e-05]\n",
      " [1.68777483e-04 4.89883157e-05 5.12616384e-05]]\n",
      "[[0.00052498 0.00014096 0.00014652]\n",
      " [0.00052674 0.00014053 0.00014645]\n",
      " [0.00010027 0.0007938  0.00067541]\n",
      " ...\n",
      " [0.00053237 0.00013905 0.00014548]\n",
      " [0.00053239 0.00013905 0.00014548]\n",
      " [0.00052087 0.0001421  0.00014747]]\n",
      "Recall                      0.8330\n",
      "Precision                   0.8920\n",
      "F1                          0.8447\n",
      "Kappa                       0.5181\n",
      "Quadratic Weighted Kappa    0.6007\n",
      "dtype: float64\n",
      "Confusion Matrix:\n",
      "     0    1  2\n",
      "0  762  119  5\n",
      "1    4  105  2\n",
      "2    1   43  1\n",
      "----------------\n",
      "RANDOM SET:  1\n",
      "Concat Value Len: 3127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 10, Loss: 3347.331055, Accuracy(train): 0.844579\n",
      "Step: 20, Loss: 3263.974854, Accuracy(train): 0.844899\n",
      "Step: 30, Loss: 3185.483398, Accuracy(train): 0.845219\n",
      "Step: 40, Loss: 3111.741943, Accuracy(train): 0.845219\n",
      "Step: 50, Loss: 3042.468018, Accuracy(train): 0.845539\n",
      "Step: 60, Loss: 2977.337402, Accuracy(train): 0.845539\n",
      "Step: 70, Loss: 2916.027588, Accuracy(train): 0.844899\n",
      "Step: 80, Loss: 2858.239746, Accuracy(train): 0.844899\n",
      "Step: 90, Loss: 2803.709961, Accuracy(train): 0.844579\n",
      "Step: 100, Loss: 2752.198975, Accuracy(train): 0.846178\n",
      "Step: 110, Loss: 2703.491699, Accuracy(train): 0.845539\n",
      "Step: 120, Loss: 2657.390381, Accuracy(train): 0.845219\n",
      "Step: 130, Loss: 2613.718750, Accuracy(train): 0.845859\n",
      "Step: 140, Loss: 2572.307617, Accuracy(train): 0.846178\n",
      "Step: 150, Loss: 2533.004639, Accuracy(train): 0.847138\n",
      "Step: 160, Loss: 2495.668213, Accuracy(train): 0.847458\n",
      "Step: 170, Loss: 2460.161377, Accuracy(train): 0.847458\n",
      "Step: 180, Loss: 2426.366699, Accuracy(train): 0.847458\n",
      "Step: 190, Loss: 2394.162354, Accuracy(train): 0.846818\n",
      "Step: 200, Loss: 2363.439453, Accuracy(train): 0.846498\n",
      "Step: 210, Loss: 2334.100586, Accuracy(train): 0.846178\n",
      "Step: 220, Loss: 2306.043945, Accuracy(train): 0.846498\n",
      "Step: 230, Loss: 2279.184326, Accuracy(train): 0.847138\n",
      "Step: 240, Loss: 2253.434326, Accuracy(train): 0.847138\n",
      "Step: 250, Loss: 2228.715576, Accuracy(train): 0.846498\n",
      "Step: 260, Loss: 2204.956055, Accuracy(train): 0.846178\n",
      "Step: 270, Loss: 2182.082031, Accuracy(train): 0.846178\n",
      "Step: 280, Loss: 2160.030762, Accuracy(train): 0.846178\n",
      "Step: 290, Loss: 2138.742676, Accuracy(train): 0.846178\n",
      "Step: 300, Loss: 2118.157959, Accuracy(train): 0.846178\n",
      "[[1.68850806e-04 4.75043522e-05 5.06312027e-05]\n",
      " [1.69659078e-04 4.72715441e-05 5.04433059e-05]\n",
      " [3.01866943e-05 2.94346017e-04 2.27828730e-04]\n",
      " ...\n",
      " [1.72092933e-04 4.65749458e-05 4.98572569e-05]\n",
      " [1.74793077e-04 4.58164327e-05 4.91949697e-05]\n",
      " [1.70625076e-04 4.70198979e-05 5.02992055e-05]]\n",
      "[[5.02972540e-04 1.45197016e-04 1.54503889e-04]\n",
      " [1.20801518e-04 6.57411912e-04 5.35613188e-04]\n",
      " [9.69945205e-05 8.29741481e-04 6.49357418e-04]\n",
      " ...\n",
      " [5.39658624e-04 1.34812762e-04 1.45459167e-04]\n",
      " [9.56975688e-05 8.41943717e-04 6.57726306e-04]\n",
      " [5.26491822e-04 1.38426004e-04 1.48761201e-04]]\n",
      "Recall                      0.8273\n",
      "Precision                   0.8864\n",
      "F1                          0.8394\n",
      "Kappa                       0.4760\n",
      "Quadratic Weighted Kappa    0.6143\n",
      "dtype: float64\n",
      "Confusion Matrix:\n",
      "     0    1  2\n",
      "0  781  120  0\n",
      "1    2   81  0\n",
      "2    1   57  0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------\n",
      "RANDOM SET:  2\n",
      "Concat Value Len: 3127\n",
      "Step: 10, Loss: 3347.910400, Accuracy(train): 0.829869\n",
      "Step: 20, Loss: 3265.105957, Accuracy(train): 0.829869\n",
      "Step: 30, Loss: 3187.122070, Accuracy(train): 0.830189\n",
      "Step: 40, Loss: 3113.850830, Accuracy(train): 0.830508\n",
      "Step: 50, Loss: 3045.049072, Accuracy(train): 0.830189\n",
      "Step: 60, Loss: 2980.426758, Accuracy(train): 0.830189\n",
      "Step: 70, Loss: 2919.663574, Accuracy(train): 0.832107\n",
      "Step: 80, Loss: 2862.470947, Accuracy(train): 0.832427\n",
      "Step: 90, Loss: 2808.581055, Accuracy(train): 0.832427\n",
      "Step: 100, Loss: 2757.753418, Accuracy(train): 0.832747\n",
      "Step: 110, Loss: 2709.772217, Accuracy(train): 0.831788\n",
      "Step: 120, Loss: 2664.431641, Accuracy(train): 0.831788\n",
      "Step: 130, Loss: 2621.548828, Accuracy(train): 0.832107\n",
      "Step: 140, Loss: 2580.950684, Accuracy(train): 0.831788\n",
      "Step: 150, Loss: 2542.471924, Accuracy(train): 0.832427\n",
      "Step: 160, Loss: 2505.966064, Accuracy(train): 0.832427\n",
      "Step: 170, Loss: 2471.294434, Accuracy(train): 0.832747\n",
      "Step: 180, Loss: 2438.323730, Accuracy(train): 0.832747\n",
      "Step: 190, Loss: 2406.933838, Accuracy(train): 0.832427\n",
      "Step: 200, Loss: 2377.008057, Accuracy(train): 0.832107\n",
      "Step: 210, Loss: 2348.442871, Accuracy(train): 0.832107\n",
      "Step: 220, Loss: 2321.134521, Accuracy(train): 0.832107\n",
      "Step: 230, Loss: 2294.993896, Accuracy(train): 0.832747\n",
      "Step: 240, Loss: 2269.927246, Accuracy(train): 0.832107\n",
      "Step: 250, Loss: 2245.859375, Accuracy(train): 0.832427\n",
      "Step: 260, Loss: 2222.709229, Accuracy(train): 0.832427\n",
      "Step: 270, Loss: 2200.410400, Accuracy(train): 0.832107\n",
      "Step: 280, Loss: 2178.889893, Accuracy(train): 0.832107\n",
      "Step: 290, Loss: 2158.091797, Accuracy(train): 0.832107\n",
      "Step: 300, Loss: 2137.958252, Accuracy(train): 0.832427\n",
      "[[1.71914149e-04 4.76150755e-05 5.04323332e-05]\n",
      " [1.72824935e-04 4.73592068e-05 5.02824829e-05]\n",
      " [3.28032241e-05 2.74886033e-04 2.19224753e-04]\n",
      " ...\n",
      " [1.75346074e-04 4.66551728e-05 4.97866990e-05]\n",
      " [1.77914961e-04 4.59481495e-05 4.91992400e-05]\n",
      " [1.73937571e-04 4.70850783e-05 5.04121308e-05]]\n",
      "[[0.00017508 0.0004448  0.0003923 ]\n",
      " [0.0004755  0.00015451 0.00016185]\n",
      " [0.00050768 0.0001442  0.00015308]\n",
      " ...\n",
      " [0.0004755  0.00015451 0.00016185]\n",
      " [0.00051375 0.00014245 0.00015194]\n",
      " [0.00048556 0.00015118 0.00015939]]\n",
      "Recall                      0.8676\n",
      "Precision                   0.9199\n",
      "F1                          0.8768\n",
      "Kappa                       0.5365\n",
      "Quadratic Weighted Kappa    0.6414\n",
      "dtype: float64\n",
      "Confusion Matrix:\n",
      "     0   1  2\n",
      "0  824  89  4\n",
      "1    3  78  0\n",
      "2    0  42  2\n",
      "----------------\n",
      "RANDOM SET:  3\n",
      "Concat Value Len: 3126\n",
      "Step: 10, Loss: 3346.515381, Accuracy(train): 0.842290\n",
      "Step: 20, Loss: 3263.422852, Accuracy(train): 0.841651\n",
      "Step: 30, Loss: 3185.196777, Accuracy(train): 0.841331\n",
      "Step: 40, Loss: 3111.747559, Accuracy(train): 0.841331\n",
      "Step: 50, Loss: 3042.824707, Accuracy(train): 0.841011\n",
      "Step: 60, Loss: 2978.113770, Accuracy(train): 0.841011\n",
      "Step: 70, Loss: 2917.294922, Accuracy(train): 0.841651\n",
      "Step: 80, Loss: 2860.061523, Accuracy(train): 0.842290\n",
      "Step: 90, Loss: 2806.132324, Accuracy(train): 0.842610\n",
      "Step: 100, Loss: 2755.247314, Accuracy(train): 0.842290\n",
      "Step: 110, Loss: 2707.176758, Accuracy(train): 0.841971\n",
      "Step: 120, Loss: 2661.718262, Accuracy(train): 0.841971\n",
      "Step: 130, Loss: 2618.680664, Accuracy(train): 0.841971\n",
      "Step: 140, Loss: 2577.894531, Accuracy(train): 0.841971\n",
      "Step: 150, Loss: 2539.203125, Accuracy(train): 0.842290\n",
      "Step: 160, Loss: 2502.454346, Accuracy(train): 0.842610\n",
      "Step: 170, Loss: 2467.518799, Accuracy(train): 0.842610\n",
      "Step: 180, Loss: 2434.265625, Accuracy(train): 0.842930\n",
      "Step: 190, Loss: 2402.576172, Accuracy(train): 0.843250\n",
      "Step: 200, Loss: 2372.343018, Accuracy(train): 0.843250\n",
      "Step: 210, Loss: 2343.459961, Accuracy(train): 0.843250\n",
      "Step: 220, Loss: 2315.831787, Accuracy(train): 0.843890\n",
      "Step: 230, Loss: 2289.366211, Accuracy(train): 0.843890\n",
      "Step: 240, Loss: 2263.977051, Accuracy(train): 0.843890\n",
      "Step: 250, Loss: 2239.585205, Accuracy(train): 0.843890\n",
      "Step: 260, Loss: 2216.116699, Accuracy(train): 0.844210\n",
      "Step: 270, Loss: 2193.501709, Accuracy(train): 0.844850\n",
      "Step: 280, Loss: 2171.674316, Accuracy(train): 0.844210\n",
      "Step: 290, Loss: 2150.576660, Accuracy(train): 0.844210\n",
      "Step: 300, Loss: 2130.151367, Accuracy(train): 0.844210\n",
      "[[1.68715603e-04 4.80258227e-05 5.07050943e-05]\n",
      " [1.69953974e-04 4.76592264e-05 5.05225376e-05]\n",
      " [3.13276662e-05 2.85318536e-04 2.24140104e-04]\n",
      " ...\n",
      " [1.64390792e-04 4.93705336e-05 5.21371205e-05]\n",
      " [1.77709185e-04 4.54744097e-05 4.91057254e-05]\n",
      " [1.68412794e-04 4.81308901e-05 5.13229384e-05]]\n",
      "[[0.00050205 0.000146   0.00015539]\n",
      " [0.00051323 0.00014265 0.000153  ]\n",
      " [0.00051553 0.00014195 0.00015127]\n",
      " ...\n",
      " [0.00051553 0.00014195 0.00015127]\n",
      " [0.00052457 0.00013937 0.0001493 ]\n",
      " [0.00051642 0.00014173 0.0001525 ]]\n",
      "Recall                      0.8399\n",
      "Precision                   0.9166\n",
      "F1                          0.8486\n",
      "Kappa                       0.4965\n",
      "Quadratic Weighted Kappa    0.6282\n",
      "dtype: float64\n",
      "Confusion Matrix:\n",
      "     0    1  2\n",
      "0  794  104  0\n",
      "1    6   80  1\n",
      "2    3   53  2\n",
      "----------------\n",
      "ALL DATA:\n",
      "Recall                      0.8419\n",
      "Precision                   0.9038\n",
      "F1                          0.8523\n",
      "Kappa                       0.5065\n",
      "Quadratic Weighted Kappa    0.6208\n",
      "dtype: float64\n",
      "Confusion Matrix:\n",
      "      0    1  2\n",
      "0  3161  432  9\n",
      "1    15  344  3\n",
      "2     5  195  5\n"
     ]
    }
   ],
   "source": [
    "%run ../train/tf_pca_classify.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match test against: ./orig_data/TF_PCA-Classified-Prediction-Def-PRE-All.csv True\n",
      "Str match ratio: 1.0\n"
     ]
    }
   ],
   "source": [
    "test_file = 'TF_PCA-Classified-Prediction-Def-PRE-All.csv'\n",
    "file_cmp_diff_ratio('../data/' + test_file, './orig_data/' + test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "RANDOM SET:  0\n",
      "Concat Value Len: 3127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 10, Loss: 3194.588135, Accuracy(train): 0.838823\n",
      "Step: 20, Loss: 3015.814453, Accuracy(train): 0.838184\n",
      "Step: 30, Loss: 2883.926514, Accuracy(train): 0.839143\n",
      "Step: 40, Loss: 2784.864258, Accuracy(train): 0.840102\n",
      "Step: 50, Loss: 2708.237549, Accuracy(train): 0.841701\n",
      "Step: 60, Loss: 2646.731934, Accuracy(train): 0.842341\n",
      "Step: 70, Loss: 2595.410645, Accuracy(train): 0.844899\n",
      "Step: 80, Loss: 2550.988525, Accuracy(train): 0.846178\n",
      "Step: 90, Loss: 2511.271729, Accuracy(train): 0.847777\n",
      "Step: 100, Loss: 2474.763672, Accuracy(train): 0.849696\n",
      "Step: 110, Loss: 2440.442627, Accuracy(train): 0.851935\n",
      "Step: 120, Loss: 2407.620117, Accuracy(train): 0.851935\n",
      "Step: 130, Loss: 2375.848389, Accuracy(train): 0.855133\n",
      "Step: 140, Loss: 2344.843262, Accuracy(train): 0.856412\n",
      "Step: 150, Loss: 2314.442871, Accuracy(train): 0.858331\n",
      "Step: 160, Loss: 2284.554688, Accuracy(train): 0.858331\n",
      "Step: 170, Loss: 2255.149658, Accuracy(train): 0.859290\n",
      "Step: 180, Loss: 2226.220947, Accuracy(train): 0.860249\n",
      "Step: 190, Loss: 2197.790527, Accuracy(train): 0.860569\n",
      "Step: 200, Loss: 2169.889893, Accuracy(train): 0.861209\n",
      "Step: 210, Loss: 2142.546387, Accuracy(train): 0.861848\n",
      "Step: 220, Loss: 2115.800781, Accuracy(train): 0.863767\n",
      "Step: 230, Loss: 2089.680176, Accuracy(train): 0.863447\n",
      "Step: 240, Loss: 2064.206299, Accuracy(train): 0.864727\n",
      "Step: 250, Loss: 2039.390137, Accuracy(train): 0.865046\n",
      "Step: 260, Loss: 2015.243774, Accuracy(train): 0.865686\n",
      "Step: 270, Loss: 1991.763794, Accuracy(train): 0.866006\n",
      "Step: 280, Loss: 1968.937988, Accuracy(train): 0.866965\n",
      "Step: 290, Loss: 1946.760132, Accuracy(train): 0.868564\n",
      "Step: 300, Loss: 1925.203735, Accuracy(train): 0.871122\n",
      "Step: 310, Loss: 1904.255005, Accuracy(train): 0.871122\n",
      "Step: 320, Loss: 1883.888184, Accuracy(train): 0.873361\n",
      "Step: 330, Loss: 1864.078369, Accuracy(train): 0.875600\n",
      "Step: 340, Loss: 1844.804932, Accuracy(train): 0.875600\n",
      "Step: 350, Loss: 1826.040283, Accuracy(train): 0.876239\n",
      "Step: 360, Loss: 1807.767822, Accuracy(train): 0.875919\n",
      "Step: 370, Loss: 1789.963013, Accuracy(train): 0.876879\n",
      "Step: 380, Loss: 1772.609497, Accuracy(train): 0.879117\n",
      "Step: 390, Loss: 1755.687500, Accuracy(train): 0.880716\n",
      "Step: 400, Loss: 1739.182983, Accuracy(train): 0.881036\n",
      "Step: 410, Loss: 1723.076904, Accuracy(train): 0.881676\n",
      "Step: 420, Loss: 1707.355103, Accuracy(train): 0.884234\n",
      "Step: 430, Loss: 1692.006592, Accuracy(train): 0.885193\n",
      "Step: 440, Loss: 1677.015381, Accuracy(train): 0.887112\n",
      "Step: 450, Loss: 1662.373535, Accuracy(train): 0.888072\n",
      "Step: 460, Loss: 1648.065430, Accuracy(train): 0.888391\n",
      "Step: 470, Loss: 1634.083618, Accuracy(train): 0.889031\n",
      "Step: 480, Loss: 1620.412598, Accuracy(train): 0.889990\n",
      "Step: 490, Loss: 1607.047607, Accuracy(train): 0.889990\n",
      "Step: 500, Loss: 1593.972534, Accuracy(train): 0.890310\n",
      "Step: 510, Loss: 1581.184937, Accuracy(train): 0.889990\n",
      "Step: 520, Loss: 1568.668823, Accuracy(train): 0.890310\n",
      "Step: 530, Loss: 1556.418945, Accuracy(train): 0.890630\n",
      "Step: 540, Loss: 1544.424194, Accuracy(train): 0.891270\n",
      "Step: 550, Loss: 1532.675171, Accuracy(train): 0.891270\n",
      "Step: 560, Loss: 1521.165894, Accuracy(train): 0.891909\n",
      "Step: 570, Loss: 1509.888184, Accuracy(train): 0.892229\n",
      "Step: 580, Loss: 1498.831543, Accuracy(train): 0.892229\n",
      "Step: 590, Loss: 1487.987183, Accuracy(train): 0.893188\n",
      "Step: 600, Loss: 1477.352295, Accuracy(train): 0.893508\n",
      "Step: 610, Loss: 1466.913452, Accuracy(train): 0.893828\n",
      "Step: 620, Loss: 1456.667725, Accuracy(train): 0.894787\n",
      "Step: 630, Loss: 1446.606201, Accuracy(train): 0.894787\n",
      "Step: 640, Loss: 1436.721069, Accuracy(train): 0.894787\n",
      "Step: 650, Loss: 1427.007812, Accuracy(train): 0.895107\n",
      "Step: 660, Loss: 1417.458008, Accuracy(train): 0.895107\n",
      "Step: 670, Loss: 1408.067139, Accuracy(train): 0.895747\n",
      "Step: 680, Loss: 1398.827881, Accuracy(train): 0.895747\n",
      "Step: 690, Loss: 1389.735474, Accuracy(train): 0.896386\n",
      "Step: 700, Loss: 1380.783569, Accuracy(train): 0.897026\n",
      "Step: 710, Loss: 1371.965332, Accuracy(train): 0.897666\n",
      "Step: 720, Loss: 1363.278442, Accuracy(train): 0.897666\n",
      "Step: 730, Loss: 1354.716431, Accuracy(train): 0.897346\n",
      "Step: 740, Loss: 1346.273804, Accuracy(train): 0.898625\n",
      "Step: 750, Loss: 1337.946533, Accuracy(train): 0.898945\n",
      "Step: 760, Loss: 1329.731323, Accuracy(train): 0.898625\n",
      "Step: 770, Loss: 1321.620605, Accuracy(train): 0.898625\n",
      "Step: 780, Loss: 1313.613770, Accuracy(train): 0.898625\n",
      "Step: 790, Loss: 1305.704834, Accuracy(train): 0.899904\n",
      "Step: 800, Loss: 1297.891357, Accuracy(train): 0.900224\n",
      "[[9.61628579e-05 1.02828572e-05 1.14812072e-05]\n",
      " [5.17215007e-06 2.09956203e-04 6.83362304e-05]\n",
      " [4.68624895e-06 1.38527152e-04 1.59059747e-04]\n",
      " ...\n",
      " [1.02034560e-04 9.64939120e-06 1.19758495e-05]\n",
      " [9.98705612e-05 1.00237559e-05 1.12970330e-05]\n",
      " [1.05717473e-04 9.45550595e-06 1.22013653e-05]]\n",
      "[[1.71387548e-04 1.99623895e-05 2.00297273e-05]\n",
      " [1.79437631e-04 1.89598355e-05 2.11602384e-05]\n",
      " [3.06599077e-05 6.84239643e-05 1.04535337e-04]\n",
      " ...\n",
      " [1.85461513e-04 1.84443390e-05 2.15293966e-05]\n",
      " [1.85511917e-04 1.84393167e-05 2.15347495e-05]\n",
      " [1.73044217e-04 1.95535354e-05 2.07354587e-05]]\n",
      "Recall                      0.8858\n",
      "Precision                   0.9082\n",
      "F1                          0.8948\n",
      "Kappa                       0.6163\n",
      "Quadratic Weighted Kappa    0.6844\n",
      "dtype: float64\n",
      "Confusion Matrix:\n",
      "     0   1   2\n",
      "0  822  43  21\n",
      "1   16  72  23\n",
      "2    3  13  29\n",
      "----------------\n",
      "RANDOM SET:  1\n",
      "Concat Value Len: 3127\n",
      "Step: 10, Loss: 3186.670898, Accuracy(train): 0.834986\n",
      "Step: 20, Loss: 3000.913818, Accuracy(train): 0.836265\n",
      "Step: 30, Loss: 2862.785400, Accuracy(train): 0.838823\n",
      "Step: 40, Loss: 2758.430176, Accuracy(train): 0.839143\n",
      "Step: 50, Loss: 2677.480957, Accuracy(train): 0.840102\n",
      "Step: 60, Loss: 2612.569336, Accuracy(train): 0.841701\n",
      "Step: 70, Loss: 2558.621338, Accuracy(train): 0.842981\n",
      "Step: 80, Loss: 2512.237793, Accuracy(train): 0.843620\n",
      "Step: 90, Loss: 2471.108643, Accuracy(train): 0.845219\n",
      "Step: 100, Loss: 2433.643799, Accuracy(train): 0.845539\n",
      "Step: 110, Loss: 2398.735840, Accuracy(train): 0.844260\n",
      "Step: 120, Loss: 2365.622803, Accuracy(train): 0.845539\n",
      "Step: 130, Loss: 2333.787109, Accuracy(train): 0.846498\n",
      "Step: 140, Loss: 2302.889648, Accuracy(train): 0.848097\n",
      "Step: 150, Loss: 2272.716797, Accuracy(train): 0.848097\n",
      "Step: 160, Loss: 2243.139404, Accuracy(train): 0.848737\n",
      "Step: 170, Loss: 2214.086914, Accuracy(train): 0.848737\n",
      "Step: 180, Loss: 2185.534912, Accuracy(train): 0.849696\n",
      "Step: 190, Loss: 2157.471436, Accuracy(train): 0.850336\n",
      "Step: 200, Loss: 2129.907227, Accuracy(train): 0.851615\n",
      "Step: 210, Loss: 2102.858398, Accuracy(train): 0.852255\n",
      "Step: 220, Loss: 2076.337402, Accuracy(train): 0.851935\n",
      "Step: 230, Loss: 2050.363281, Accuracy(train): 0.854493\n",
      "Step: 240, Loss: 2024.949463, Accuracy(train): 0.855453\n",
      "Step: 250, Loss: 2000.104126, Accuracy(train): 0.856732\n",
      "Step: 260, Loss: 1975.832275, Accuracy(train): 0.858331\n",
      "Step: 270, Loss: 1952.142456, Accuracy(train): 0.859610\n",
      "Step: 280, Loss: 1929.035645, Accuracy(train): 0.861529\n",
      "Step: 290, Loss: 1906.509155, Accuracy(train): 0.862488\n",
      "Step: 300, Loss: 1884.559326, Accuracy(train): 0.863447\n",
      "Step: 310, Loss: 1863.181763, Accuracy(train): 0.864407\n",
      "Step: 320, Loss: 1842.368774, Accuracy(train): 0.864407\n",
      "Step: 330, Loss: 1822.110474, Accuracy(train): 0.864407\n",
      "Step: 340, Loss: 1802.397827, Accuracy(train): 0.867605\n",
      "Step: 350, Loss: 1783.215454, Accuracy(train): 0.867605\n",
      "Step: 360, Loss: 1764.551758, Accuracy(train): 0.868884\n",
      "Step: 370, Loss: 1746.392212, Accuracy(train): 0.871762\n",
      "Step: 380, Loss: 1728.720459, Accuracy(train): 0.874320\n",
      "Step: 390, Loss: 1711.523560, Accuracy(train): 0.877518\n",
      "Step: 400, Loss: 1694.787598, Accuracy(train): 0.879437\n",
      "Step: 410, Loss: 1678.493652, Accuracy(train): 0.881995\n",
      "Step: 420, Loss: 1662.631348, Accuracy(train): 0.882315\n",
      "Step: 430, Loss: 1647.183472, Accuracy(train): 0.883275\n",
      "Step: 440, Loss: 1632.138550, Accuracy(train): 0.883595\n",
      "Step: 450, Loss: 1617.483521, Accuracy(train): 0.884874\n",
      "Step: 460, Loss: 1603.203369, Accuracy(train): 0.886473\n",
      "Step: 470, Loss: 1589.288940, Accuracy(train): 0.887432\n",
      "Step: 480, Loss: 1575.726685, Accuracy(train): 0.887432\n",
      "Step: 490, Loss: 1562.504150, Accuracy(train): 0.888072\n",
      "Step: 500, Loss: 1549.612915, Accuracy(train): 0.888072\n",
      "Step: 510, Loss: 1537.039673, Accuracy(train): 0.888711\n",
      "Step: 520, Loss: 1524.774658, Accuracy(train): 0.889031\n",
      "Step: 530, Loss: 1512.807495, Accuracy(train): 0.889990\n",
      "Step: 540, Loss: 1501.130859, Accuracy(train): 0.889990\n",
      "Step: 550, Loss: 1489.730103, Accuracy(train): 0.889990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 560, Loss: 1478.599731, Accuracy(train): 0.889990\n",
      "Step: 570, Loss: 1467.729736, Accuracy(train): 0.889671\n",
      "Step: 580, Loss: 1457.111084, Accuracy(train): 0.889671\n",
      "Step: 590, Loss: 1446.735596, Accuracy(train): 0.889351\n",
      "Step: 600, Loss: 1436.594849, Accuracy(train): 0.889671\n",
      "Step: 610, Loss: 1426.681519, Accuracy(train): 0.889990\n",
      "Step: 620, Loss: 1416.985840, Accuracy(train): 0.889990\n",
      "Step: 630, Loss: 1407.500244, Accuracy(train): 0.889990\n",
      "Step: 640, Loss: 1398.217773, Accuracy(train): 0.890950\n",
      "Step: 650, Loss: 1389.132446, Accuracy(train): 0.891589\n",
      "Step: 660, Loss: 1380.234619, Accuracy(train): 0.891589\n",
      "Step: 670, Loss: 1371.519165, Accuracy(train): 0.892869\n",
      "Step: 680, Loss: 1362.980103, Accuracy(train): 0.894148\n",
      "Step: 690, Loss: 1354.610107, Accuracy(train): 0.893828\n",
      "Step: 700, Loss: 1346.403809, Accuracy(train): 0.894468\n",
      "Step: 710, Loss: 1338.352905, Accuracy(train): 0.894787\n",
      "Step: 720, Loss: 1330.453369, Accuracy(train): 0.895107\n",
      "Step: 730, Loss: 1322.700195, Accuracy(train): 0.896386\n",
      "Step: 740, Loss: 1315.086304, Accuracy(train): 0.898305\n",
      "Step: 750, Loss: 1307.607666, Accuracy(train): 0.898945\n",
      "Step: 760, Loss: 1300.260132, Accuracy(train): 0.899584\n",
      "Step: 770, Loss: 1293.035767, Accuracy(train): 0.898945\n",
      "Step: 780, Loss: 1285.932251, Accuracy(train): 0.899264\n",
      "Step: 790, Loss: 1278.944946, Accuracy(train): 0.901183\n",
      "Step: 800, Loss: 1272.068481, Accuracy(train): 0.900544\n",
      "[[3.03662563e-05 2.96471370e-06 3.29595500e-06]\n",
      " [3.10861548e-05 2.86966129e-06 3.42160920e-06]\n",
      " [5.52475895e-06 1.38020211e-05 1.31683435e-05]\n",
      " ...\n",
      " [3.20085243e-05 2.78573612e-06 3.49623691e-06]\n",
      " [3.17241817e-05 2.88629888e-06 3.26979282e-06]\n",
      " [3.27428945e-05 2.78478178e-06 3.44745520e-06]]\n",
      "[[1.08767030e-04 1.00850963e-05 1.20846010e-05]\n",
      " [5.54624449e-06 2.18498136e-04 7.94380681e-05]\n",
      " [3.68828670e-06 2.62039470e-04 1.83356415e-04]\n",
      " ...\n",
      " [1.14488553e-04 9.69431254e-06 1.19418601e-05]\n",
      " [1.93241751e-05 4.82758930e-05 4.60594532e-05]\n",
      " [1.16376045e-04 9.58329106e-06 1.22017267e-05]]\n",
      "Recall                      0.8877\n",
      "Precision                   0.9100\n",
      "F1                          0.8957\n",
      "Kappa                       0.5907\n",
      "Quadratic Weighted Kappa    0.6780\n",
      "dtype: float64\n",
      "Confusion Matrix:\n",
      "     0   1   2\n",
      "0  834  55  12\n",
      "1   16  60   7\n",
      "2    9  18  31\n",
      "----------------\n",
      "RANDOM SET:  2\n",
      "Concat Value Len: 3127\n",
      "Step: 10, Loss: 3187.080566, Accuracy(train): 0.827950\n",
      "Step: 20, Loss: 3002.814209, Accuracy(train): 0.828910\n",
      "Step: 30, Loss: 2867.834229, Accuracy(train): 0.829549\n",
      "Step: 40, Loss: 2767.278809, Accuracy(train): 0.828270\n",
      "Step: 50, Loss: 2689.554199, Accuracy(train): 0.826671\n",
      "Step: 60, Loss: 2626.715576, Accuracy(train): 0.827630\n",
      "Step: 70, Loss: 2573.624512, Accuracy(train): 0.828910\n",
      "Step: 80, Loss: 2527.085938, Accuracy(train): 0.831148\n",
      "Step: 90, Loss: 2485.075684, Accuracy(train): 0.833067\n",
      "Step: 100, Loss: 2446.261719, Accuracy(train): 0.833067\n",
      "Step: 110, Loss: 2409.736572, Accuracy(train): 0.836265\n",
      "Step: 120, Loss: 2374.888916, Accuracy(train): 0.836904\n",
      "Step: 130, Loss: 2341.309326, Accuracy(train): 0.838503\n",
      "Step: 140, Loss: 2308.744629, Accuracy(train): 0.837864\n",
      "Step: 150, Loss: 2277.043213, Accuracy(train): 0.837224\n",
      "Step: 160, Loss: 2246.122070, Accuracy(train): 0.837544\n",
      "Step: 170, Loss: 2215.938477, Accuracy(train): 0.840742\n",
      "Step: 180, Loss: 2186.476562, Accuracy(train): 0.842341\n",
      "Step: 190, Loss: 2157.733887, Accuracy(train): 0.844899\n",
      "Step: 200, Loss: 2129.709961, Accuracy(train): 0.847138\n",
      "Step: 210, Loss: 2102.403809, Accuracy(train): 0.848417\n",
      "Step: 220, Loss: 2075.815430, Accuracy(train): 0.849696\n",
      "Step: 230, Loss: 2049.942139, Accuracy(train): 0.851295\n",
      "Step: 240, Loss: 2024.771118, Accuracy(train): 0.852255\n",
      "Step: 250, Loss: 2000.296753, Accuracy(train): 0.852574\n",
      "Step: 260, Loss: 1976.505005, Accuracy(train): 0.854173\n",
      "Step: 270, Loss: 1953.377197, Accuracy(train): 0.854173\n",
      "Step: 280, Loss: 1930.900513, Accuracy(train): 0.853854\n",
      "Step: 290, Loss: 1909.057983, Accuracy(train): 0.854173\n",
      "Step: 300, Loss: 1887.824341, Accuracy(train): 0.856092\n",
      "Step: 310, Loss: 1867.186401, Accuracy(train): 0.857371\n",
      "Step: 320, Loss: 1847.117676, Accuracy(train): 0.857691\n",
      "Step: 330, Loss: 1827.605347, Accuracy(train): 0.859930\n",
      "Step: 340, Loss: 1808.624634, Accuracy(train): 0.861848\n",
      "Step: 350, Loss: 1790.157471, Accuracy(train): 0.864087\n",
      "Step: 360, Loss: 1772.186890, Accuracy(train): 0.864087\n",
      "Step: 370, Loss: 1754.693237, Accuracy(train): 0.866006\n",
      "Step: 380, Loss: 1737.661865, Accuracy(train): 0.867605\n",
      "Step: 390, Loss: 1721.071411, Accuracy(train): 0.869204\n",
      "Step: 400, Loss: 1704.914307, Accuracy(train): 0.870163\n",
      "Step: 410, Loss: 1689.174561, Accuracy(train): 0.872082\n",
      "Step: 420, Loss: 1673.834839, Accuracy(train): 0.875600\n",
      "Step: 430, Loss: 1658.882690, Accuracy(train): 0.875919\n",
      "Step: 440, Loss: 1644.306763, Accuracy(train): 0.876239\n",
      "Step: 450, Loss: 1630.095215, Accuracy(train): 0.876559\n",
      "Step: 460, Loss: 1616.232178, Accuracy(train): 0.877518\n",
      "Step: 470, Loss: 1602.712646, Accuracy(train): 0.878798\n",
      "Step: 480, Loss: 1589.518555, Accuracy(train): 0.879437\n",
      "Step: 490, Loss: 1576.643799, Accuracy(train): 0.880716\n",
      "Step: 500, Loss: 1564.072876, Accuracy(train): 0.880397\n",
      "Step: 510, Loss: 1551.801147, Accuracy(train): 0.881036\n",
      "Step: 520, Loss: 1539.813599, Accuracy(train): 0.880397\n",
      "Step: 530, Loss: 1528.104248, Accuracy(train): 0.880716\n",
      "Step: 540, Loss: 1516.659058, Accuracy(train): 0.881676\n",
      "Step: 550, Loss: 1505.471802, Accuracy(train): 0.882635\n",
      "Step: 560, Loss: 1494.531494, Accuracy(train): 0.882315\n",
      "Step: 570, Loss: 1483.831299, Accuracy(train): 0.882955\n",
      "Step: 580, Loss: 1473.360840, Accuracy(train): 0.882955\n",
      "Step: 590, Loss: 1463.113892, Accuracy(train): 0.883595\n",
      "Step: 600, Loss: 1453.079834, Accuracy(train): 0.884234\n",
      "Step: 610, Loss: 1443.251221, Accuracy(train): 0.884874\n",
      "Step: 620, Loss: 1433.621460, Accuracy(train): 0.886473\n",
      "Step: 630, Loss: 1424.182983, Accuracy(train): 0.886792\n",
      "Step: 640, Loss: 1414.928467, Accuracy(train): 0.888072\n",
      "Step: 650, Loss: 1405.850098, Accuracy(train): 0.888391\n",
      "Step: 660, Loss: 1396.943359, Accuracy(train): 0.889031\n",
      "Step: 670, Loss: 1388.199097, Accuracy(train): 0.889671\n",
      "Step: 680, Loss: 1379.612427, Accuracy(train): 0.890630\n",
      "Step: 690, Loss: 1371.177490, Accuracy(train): 0.891270\n",
      "Step: 700, Loss: 1362.887329, Accuracy(train): 0.890630\n",
      "Step: 710, Loss: 1354.737305, Accuracy(train): 0.891589\n",
      "Step: 720, Loss: 1346.722290, Accuracy(train): 0.892229\n",
      "Step: 730, Loss: 1338.835327, Accuracy(train): 0.892869\n",
      "Step: 740, Loss: 1331.072632, Accuracy(train): 0.893188\n",
      "Step: 750, Loss: 1323.428833, Accuracy(train): 0.894148\n",
      "Step: 760, Loss: 1315.899902, Accuracy(train): 0.894148\n",
      "Step: 770, Loss: 1308.479858, Accuracy(train): 0.894468\n",
      "Step: 780, Loss: 1301.166626, Accuracy(train): 0.894787\n",
      "Step: 790, Loss: 1293.952881, Accuracy(train): 0.894787\n",
      "Step: 800, Loss: 1286.835571, Accuracy(train): 0.894468\n",
      "[[6.55020383e-05 6.85767355e-06 7.15422559e-06]\n",
      " [6.84859882e-05 6.52058491e-06 7.54451175e-06]\n",
      " [1.19161758e-05 2.83195106e-05 3.65769104e-05]\n",
      " ...\n",
      " [7.21006973e-05 6.19162219e-06 7.91517506e-06]\n",
      " [7.02718469e-05 6.46084860e-06 7.46400450e-06]\n",
      " [7.40739263e-05 6.12618322e-06 8.01941118e-06]]\n",
      "[[8.93017554e-05 1.01856936e-04 3.43352189e-05]\n",
      " [2.85774666e-04 2.79778171e-05 3.20434998e-05]\n",
      " [2.93978725e-04 2.75775478e-05 3.12464207e-05]\n",
      " ...\n",
      " [2.85774666e-04 2.79778171e-05 3.20434998e-05]\n",
      " [3.14781984e-04 2.56006779e-05 3.36912524e-05]\n",
      " [2.96221256e-04 2.72112198e-05 3.25639864e-05]]\n",
      "Recall                      0.9079\n",
      "Precision                   0.9159\n",
      "F1                          0.9115\n",
      "Kappa                       0.6039\n",
      "Quadratic Weighted Kappa    0.6699\n",
      "dtype: float64\n",
      "Confusion Matrix:\n",
      "     0   1   2\n",
      "0  870  31  16\n",
      "1   22  50   9\n",
      "2    6  12  26\n",
      "----------------\n",
      "RANDOM SET:  3\n",
      "Concat Value Len: 3126\n",
      "Step: 10, Loss: 3190.897949, Accuracy(train): 0.834613\n",
      "Step: 20, Loss: 3009.384766, Accuracy(train): 0.834933\n",
      "Step: 30, Loss: 2874.465820, Accuracy(train): 0.833333\n",
      "Step: 40, Loss: 2772.691895, Accuracy(train): 0.832374\n",
      "Step: 50, Loss: 2693.888672, Accuracy(train): 0.835253\n",
      "Step: 60, Loss: 2630.689209, Accuracy(train): 0.833973\n",
      "Step: 70, Loss: 2578.049805, Accuracy(train): 0.835892\n",
      "Step: 80, Loss: 2532.602051, Accuracy(train): 0.837812\n",
      "Step: 90, Loss: 2492.059326, Accuracy(train): 0.838132\n",
      "Step: 100, Loss: 2454.890137, Accuracy(train): 0.841011\n",
      "Step: 110, Loss: 2420.070801, Accuracy(train): 0.842930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 120, Loss: 2386.916992, Accuracy(train): 0.843890\n",
      "Step: 130, Loss: 2354.987305, Accuracy(train): 0.845489\n",
      "Step: 140, Loss: 2323.999512, Accuracy(train): 0.847729\n",
      "Step: 150, Loss: 2293.781738, Accuracy(train): 0.849008\n",
      "Step: 160, Loss: 2264.236816, Accuracy(train): 0.850288\n",
      "Step: 170, Loss: 2235.317383, Accuracy(train): 0.849968\n",
      "Step: 180, Loss: 2206.993652, Accuracy(train): 0.850608\n",
      "Step: 190, Loss: 2179.264160, Accuracy(train): 0.851568\n",
      "Step: 200, Loss: 2152.130371, Accuracy(train): 0.853807\n",
      "Step: 210, Loss: 2125.589111, Accuracy(train): 0.854447\n",
      "Step: 220, Loss: 2099.648438, Accuracy(train): 0.854447\n",
      "Step: 230, Loss: 2074.303711, Accuracy(train): 0.855726\n",
      "Step: 240, Loss: 2049.554932, Accuracy(train): 0.857006\n",
      "Step: 250, Loss: 2025.397827, Accuracy(train): 0.859245\n",
      "Step: 260, Loss: 2001.827759, Accuracy(train): 0.859565\n",
      "Step: 270, Loss: 1978.836182, Accuracy(train): 0.860525\n",
      "Step: 280, Loss: 1956.422729, Accuracy(train): 0.860205\n",
      "Step: 290, Loss: 1934.570557, Accuracy(train): 0.860845\n",
      "Step: 300, Loss: 1913.276611, Accuracy(train): 0.863084\n",
      "Step: 310, Loss: 1892.527832, Accuracy(train): 0.862764\n",
      "Step: 320, Loss: 1872.310059, Accuracy(train): 0.863084\n",
      "Step: 330, Loss: 1852.614746, Accuracy(train): 0.865963\n",
      "Step: 340, Loss: 1833.427124, Accuracy(train): 0.866603\n",
      "Step: 350, Loss: 1814.732666, Accuracy(train): 0.867242\n",
      "Step: 360, Loss: 1796.514282, Accuracy(train): 0.866603\n",
      "Step: 370, Loss: 1778.760376, Accuracy(train): 0.868202\n",
      "Step: 380, Loss: 1761.451050, Accuracy(train): 0.870761\n",
      "Step: 390, Loss: 1744.572998, Accuracy(train): 0.874600\n",
      "Step: 400, Loss: 1728.112427, Accuracy(train): 0.876520\n",
      "Step: 410, Loss: 1712.053223, Accuracy(train): 0.877799\n",
      "Step: 420, Loss: 1696.383057, Accuracy(train): 0.880038\n",
      "Step: 430, Loss: 1681.088379, Accuracy(train): 0.881318\n",
      "Step: 440, Loss: 1666.156494, Accuracy(train): 0.883557\n",
      "Step: 450, Loss: 1651.574097, Accuracy(train): 0.884517\n",
      "Step: 460, Loss: 1637.329224, Accuracy(train): 0.884837\n",
      "Step: 470, Loss: 1623.412842, Accuracy(train): 0.886116\n",
      "Step: 480, Loss: 1609.812500, Accuracy(train): 0.885477\n",
      "Step: 490, Loss: 1596.519531, Accuracy(train): 0.886436\n",
      "Step: 500, Loss: 1583.525146, Accuracy(train): 0.886436\n",
      "Step: 510, Loss: 1570.815918, Accuracy(train): 0.886756\n",
      "Step: 520, Loss: 1558.383789, Accuracy(train): 0.888036\n",
      "Step: 530, Loss: 1546.223755, Accuracy(train): 0.888356\n",
      "Step: 540, Loss: 1534.322998, Accuracy(train): 0.888676\n",
      "Step: 550, Loss: 1522.674316, Accuracy(train): 0.888676\n",
      "Step: 560, Loss: 1511.270020, Accuracy(train): 0.888996\n",
      "Step: 570, Loss: 1500.101318, Accuracy(train): 0.888996\n",
      "Step: 580, Loss: 1489.160156, Accuracy(train): 0.890595\n",
      "Step: 590, Loss: 1478.438354, Accuracy(train): 0.889955\n",
      "Step: 600, Loss: 1467.930664, Accuracy(train): 0.890595\n",
      "Step: 610, Loss: 1457.627930, Accuracy(train): 0.892514\n",
      "Step: 620, Loss: 1447.522949, Accuracy(train): 0.892514\n",
      "Step: 630, Loss: 1437.608643, Accuracy(train): 0.893474\n",
      "Step: 640, Loss: 1427.880615, Accuracy(train): 0.894114\n",
      "Step: 650, Loss: 1418.328125, Accuracy(train): 0.894434\n",
      "Step: 660, Loss: 1408.948730, Accuracy(train): 0.895713\n",
      "Step: 670, Loss: 1399.735352, Accuracy(train): 0.896033\n",
      "Step: 680, Loss: 1390.680542, Accuracy(train): 0.896353\n",
      "Step: 690, Loss: 1381.778076, Accuracy(train): 0.896673\n",
      "Step: 700, Loss: 1373.024536, Accuracy(train): 0.897953\n",
      "Step: 710, Loss: 1364.413818, Accuracy(train): 0.898273\n",
      "Step: 720, Loss: 1355.938843, Accuracy(train): 0.898273\n",
      "Step: 730, Loss: 1347.596069, Accuracy(train): 0.897953\n",
      "Step: 740, Loss: 1339.382080, Accuracy(train): 0.899872\n",
      "Step: 750, Loss: 1331.288208, Accuracy(train): 0.900192\n",
      "Step: 760, Loss: 1323.313110, Accuracy(train): 0.900512\n",
      "Step: 770, Loss: 1315.449951, Accuracy(train): 0.900832\n",
      "Step: 780, Loss: 1307.698364, Accuracy(train): 0.900832\n",
      "Step: 790, Loss: 1300.049561, Accuracy(train): 0.901152\n",
      "Step: 800, Loss: 1292.502808, Accuracy(train): 0.901472\n",
      "[[6.03772237e-05 6.64643169e-06 7.32698546e-06]\n",
      " [6.34528902e-05 6.30577459e-06 7.44365416e-06]\n",
      " [1.02645896e-05 2.85258563e-05 3.84285010e-05]\n",
      " ...\n",
      " [6.29125383e-05 6.40056426e-06 7.56903401e-06]\n",
      " [6.86908733e-05 5.85919267e-06 7.27604947e-06]\n",
      " [6.49231122e-05 6.22968155e-06 7.43056027e-06]]\n",
      "[[2.70743245e-04 2.45468700e-05 3.06107570e-05]\n",
      " [2.68565750e-04 2.49278519e-05 2.95945669e-05]\n",
      " [2.71630723e-04 2.42757564e-05 3.02973324e-05]\n",
      " ...\n",
      " [2.71630723e-04 2.42757564e-05 3.02973324e-05]\n",
      " [2.61586580e-04 2.54304332e-05 2.90542603e-05]\n",
      " [2.77944570e-04 2.40514657e-05 2.98432238e-05]]\n",
      "Recall                      0.8888\n",
      "Precision                   0.9066\n",
      "F1                          0.8958\n",
      "Kappa                       0.5974\n",
      "Quadratic Weighted Kappa    0.6856\n",
      "dtype: float64\n",
      "Confusion Matrix:\n",
      "     0   1   2\n",
      "0  838  45  15\n",
      "1   16  59  12\n",
      "2    7  21  30\n",
      "----------------\n",
      "ALL DATA:\n",
      "Recall                      0.8925\n",
      "Precision                   0.9086\n",
      "F1                          0.8992\n",
      "Kappa                       0.6027\n",
      "Quadratic Weighted Kappa    0.6803\n",
      "dtype: float64\n",
      "Confusion Matrix:\n",
      "      0    1    2\n",
      "0  3364  174   64\n",
      "1    70  241   51\n",
      "2    25   64  116\n"
     ]
    }
   ],
   "source": [
    "%run ../train/tf_log_regress_classify.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match test against: ./orig_data/TF_Log_Reg-Classified-Prediction-Def-PRE-All.csv True\n",
      "Str match ratio: 1.0\n"
     ]
    }
   ],
   "source": [
    "test_file = 'TF_Log_Reg-Classified-Prediction-Def-PRE-All.csv'\n",
    "file_cmp_diff_ratio('../data/' + test_file, './orig_data/' + test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "RANDOM SET:  0\n",
      "Concat Value Len: 3127\n",
      "Best parameters: {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'n_estimators': 100}\n",
      "Best score: 0.934\n",
      "Recall                      0.9232\n",
      "Precision                   0.9206\n",
      "F1                          0.9171\n",
      "Kappa                       0.6761\n",
      "Quadratic Weighted Kappa    0.7544\n",
      "dtype: float64\n",
      "Confusion Matrix:\n",
      "     0   1   2\n",
      "0  876   7   3\n",
      "1   37  56  18\n",
      "2   11   4  30\n",
      "----------------\n",
      "RANDOM SET:  1\n",
      "Concat Value Len: 3127\n",
      "Best parameters: {'max_depth': None, 'max_features': 1, 'min_samples_leaf': 1, 'n_estimators': 100}\n",
      "Best score: 0.936\n",
      "Recall                      0.9367\n",
      "Precision                   0.9333\n",
      "F1                          0.9326\n",
      "Kappa                       0.7138\n",
      "Quadratic Weighted Kappa    0.7495\n",
      "dtype: float64\n",
      "Confusion Matrix:\n",
      "     0   1   2\n",
      "0  889   9   3\n",
      "1   25  56   2\n",
      "2   15  12  31\n",
      "----------------\n",
      "RANDOM SET:  2\n",
      "Concat Value Len: 3127\n",
      "Best parameters: {'max_depth': 10, 'max_features': None, 'min_samples_leaf': 2, 'n_estimators': 100}\n",
      "Best score: 0.931\n",
      "Recall                      0.9376\n",
      "Precision                   0.9322\n",
      "F1                          0.9333\n",
      "Kappa                       0.6802\n",
      "Quadratic Weighted Kappa    0.7263\n",
      "dtype: float64\n",
      "Confusion Matrix:\n",
      "     0   1   2\n",
      "0  904   8   5\n",
      "1   31  47   3\n",
      "2   11   7  26\n",
      "----------------\n",
      "RANDOM SET:  3\n",
      "Concat Value Len: 3126\n",
      "Best parameters: {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1, 'n_estimators': 100}\n",
      "Best score: 0.934\n",
      "Recall                      0.9281\n",
      "Precision                   0.9213\n",
      "F1                          0.9222\n",
      "Kappa                       0.6730\n",
      "Quadratic Weighted Kappa    0.7375\n",
      "dtype: float64\n",
      "Confusion Matrix:\n",
      "     0   1   2\n",
      "0  887   8   3\n",
      "1   34  48   5\n",
      "2   15  10  33\n",
      "----------------\n",
      "ALL DATA:\n",
      "Recall                      0.9314\n",
      "Precision                   0.9251\n",
      "F1                          0.9264\n",
      "Kappa                       0.6858\n",
      "Quadratic Weighted Kappa    0.7427\n",
      "dtype: float64\n",
      "Confusion Matrix:\n",
      "      0    1    2\n",
      "0  3556   32   14\n",
      "1   127  207   28\n",
      "2    52   33  120\n",
      "Wall time: 5min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%run ../train/RF_classify.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match test against: ./orig_data/RF_Classified-Prediction-Def-PRE-All.csv True\n",
      "Str match ratio: 1.0\n"
     ]
    }
   ],
   "source": [
    "test_file = 'RF_Classified-Prediction-Def-PRE-All.csv'\n",
    "file_cmp_diff_ratio('../data/' + test_file, './orig_data/' + test_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
