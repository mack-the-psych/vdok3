{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "Put a path file like \"vdok-custom.pth\" into any of your sys.path directories\n",
    "(e.g. C:\\Users\\macks\\Anaconda3\\Lib\\site-packages).\n",
    "\n",
    "# vdok-custom.pth ###############################\n",
    "\n",
    "C:\\Users\\macks\\Documents\\Research\\MELVA-S\\vdok3\\prep\n",
    "C:\\Users\\macks\\Documents\\Research\\MELVA-S\\vdok3\\extract\n",
    "C:\\Users\\macks\\Documents\\Research\\MELVA-S\\vdok3\\process\n",
    "C:\\Users\\macks\\Documents\\Research\\MELVA-S\\vdok3\\reorganize\n",
    "C:\\Users\\macks\\Documents\\Research\\MELVA-S\\vdok3\\train\n",
    "\n",
    "###################################################\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Pre_Col_Name          Content Student_Question_Index\n",
      "0  Definition-Question         Inventor          2001-Inventor\n",
      "1    Definition-Answer  To invent stuff          2001-Inventor\n",
      "          Pre_Col_Name                      Content Student_Question_Index\n",
      "0  Definition-Question                         Hero              2001-Hero\n",
      "1    Definition-Answer  Someone that saves a person              2001-Hero\n",
      "          Pre_Col_Name                         Content Student_Question_Index\n",
      "0  Definition-Question                      Impossible        2001-Impossible\n",
      "1    Definition-Answer  Something that is not possible        2001-Impossible\n",
      "          Pre_Col_Name                  Content Student_Question_Index\n",
      "0  Definition-Question                 To erupt          2001-To erupt\n",
      "1    Definition-Answer  When something explodes          2001-To erupt\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../data/'\n",
    "src_file = 'Head4-Serialized-Def-ELVA.PILOT.POST-TEST.csv'\n",
    "data_file = 'EN-QA-Head4-Serialized-Def-ELVA.PILOT.POST-TEST.csv'\n",
    "def_file = 'Questin_ID_Definition.csv'\n",
    "\n",
    "from qa_serializer_lang_selector import qa_serializer_lang_selector\n",
    "\n",
    "q = qa_serializer_lang_selector(data_dir)\n",
    "q.serialize_record(src_file, r'Definition')\n",
    "q.select_lang([1], r'Definition').to_csv(data_dir + data_file, encoding= 'latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_non_extracted_stop_word(df_ac, stop_words):\n",
    "    stop_words_buf = stop_words[:]\n",
    "    for x in stop_words:\n",
    "        if not df_ac.columns.isin([x]).any():\n",
    "            print('Remove Stop Word: ', x)\n",
    "            stop_words_buf.remove(x)\n",
    "    return stop_words_buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Inventor', 'NN')]\n",
      "[('To', 'TO'), ('invent', 'VB'), ('stuff', 'NN')]\n",
      "[('Hero', 'NN')]\n",
      "[('Someone', 'NN'), ('that', 'WDT'), ('saves', 'VBZ'), ('a', 'DT'), ('person', 'NN')]\n",
      "[('Impossible', 'JJ')]\n",
      "[('Something', 'VBG'), ('that', 'DT'), ('is', 'VBZ'), ('not', 'RB'), ('possible', 'JJ')]\n",
      "[('To', 'TO'), ('erupt', 'VB')]\n",
      "[('When', 'WRB'), ('something', 'NN'), ('explodes', 'NNS')]\n",
      "inventor\n",
      "to invent stuff\n",
      "hero\n",
      "someone that save a person\n",
      "impossible\n",
      "something that be not possible\n",
      "to erupt\n",
      "when something explode\n",
      "inventor inventor discoverer artificer\n",
      "to invent stuff invent contrive devise excogitate formulate forge fabricate manufacture cook_up make_up invent material stuff stuff stuff clobber stuff stuff_and_nonsense hooey poppycock stuff stuff stuff stuff thrust stuff shove squeeze stuff lug choke_up block gorge ingurgitate overindulge glut englut stuff engorge overgorge overeat gormandize gormandise gourmandize binge pig_out satiate scarf_out stuff stuff farce stuff\n",
      "hero hero hero champion fighter hero paladin Hero Heron Hero_of_Alexandria hero Hero bomber grinder hero hero_sandwich hoagie hoagy Cuban_sandwich Italian_sandwich poor_boy sub submarine submarine_sandwich torpedo wedge zep\n",
      "someone that save a person person individual someone somebody mortal soul save salvage salve relieve save save preserve save carry_through pull_through bring_through save save lay_aside save_up save make_unnecessary deliver redeem save spare save save economize economise keep_open hold_open keep save write save angstrom angstrom_unit A vitamin_A antiophthalmic_factor axerophthol A deoxyadenosine_monophosphate A adenine A ampere amp A A a A type_A group_A person individual someone somebody mortal soul person person\n",
      "impossible impossible impossible impossible inconceivable out_of_the_question unimaginable impossible insufferable unacceptable unsufferable\n",
      "something that be not possible beryllium Be glucinium atomic_number_4 be be be exist be be equal be constitute represent make_up comprise be be follow embody be personify be be live be cost be not non possible possible possible potential possible\n",
      "to erupt erupt break_out erupt irrupt flare_up flare break_open burst_out erupt ignite catch_fire take_fire combust conflagrate erupt come_out break_through push_through erupt belch extravasate break burst erupt erupt erupt recrudesce break_out\n",
      "when something explode explode detonate blow_up set_off explode burst explode explode burst_forth break_loose explode explode explode explode detonate explode blow_up explode irrupt\n",
      "creator\n",
      "create_by_mental_act create_mentally think_up think_of dream_up hatch concoct substance object physical_object personal_property personal_estate personalty private_property nonsense bunk nonsensicality meaninglessness hokum quality information info kernel substance core center centre essence gist heart heart_and_soul inwardness marrow meat nub pith sum nitty-gritty cram push force clog choke_off clog_up back_up congest choke foul eat impregnate saturate fill fill_up make_full fill fill_up make_full\n",
      "leader character role theatrical_role part persona defender guardian protector shielder mythical_being sandwich\n",
      "causal_agent cause causal_agency organism being prevention bar rescue deliver keep hold_on prevent forestall foreclose preclude forbid refrain forbear spend expend drop reserve hold book record tape metric_linear_unit fat-soluble_vitamin nucleotide base purine current_unit letter letter_of_the_alphabet alphabetic_character blood_group blood_type causal_agent cause causal_agency organism being human_body physical_body material_body soma build figure physique anatomy shape bod chassis frame form flesh grammatical_category syntactic_category\n",
      "impossibility impossible_action\n",
      "metallic_element metal typify symbolize symbolise stand_for represent take occupy use_up stay remain rest be possibility possible_action opening applicant applier\n",
      "begin start intensify deepen change_state turn appear explode burst express_emotion express_feelings appear trouble ail pain\n",
      "change_integrity change_integrity react respond change_state turn destroy ruin pronounce articulate enounce sound_out enunciate say condemn disprove confute increase\n",
      "patentee\n",
      "confabulate mythologize mythologise spin trump_up concoct vamp vamp_up abrasive abradant abrasive_material adhesive_material adhesive_agent adhesive aggregate ammunition animal_material atom molecule particle corpuscle mote speck ballast bedding_material bedding litter bimetal builder detergent_builder chemical chemical_substance coloring_material colouring_material color colour composite_material conductor contaminant contamination detritus diamagnet discharge emission dust earth ground elastomer fiber fibre filling fill floccule floc fluff foam HAZMAT homogenate humate impregnation insulator dielectric nonconductor mineral packing_material packing wadding paper particulate particulate_matter plant_material plant_substance precursor radioactive_material raw_material staple rind rock stone sealing_material sorbate sorbent sorbent_material thickening thickener toner transparent_substance translucent_substance undercut vernix vernix_caseosa wad waste waste_material waste_matter waste_product doodad doohickey doojigger gimmick gizmo gismo gubbins thingamabob thingumabob thingmabob thingamajig thingumajig thingmajig thingummy whatchamacallit whatchamacallum whatsis widget etcetera sundries jam jampack ram chock_up cram wad overstuff pad fill_out cork\n",
      "\n",
      "abator abjurer abomination abstainer abstinent nondrinker achiever winner success succeeder acquaintance friend acquirer active actor doer worker adjudicator admirer adoptee adult grownup adventurer venturer adversary antagonist opponent opposer resister advisee advocate advocator proponent exponent affiant African agnostic doubter amateur Amerindian Native_American ancient anomaly unusual_person anti-American anti applicant applier appointee appointment appreciator apprehender Aquarius Water_Bearer archaist Aries Ram arrogator assessee asthmatic authority autodidact baby_boomer boomer baby_buster buster bad_guy bad_person baldhead baldpate baldy balker baulker noncompliant bather beard bedfellow bereaved bereaved_person best topper birth biter Black Black_person blackamoor Negro Negroid blogger blond blonde bluecoat bodybuilder muscle_builder muscle-builder musclebuilder muscleman bomber brunet brunette bullfighter toreador buster Cancer Crab candidate prospect capitalist Capricorn Goat captor capturer case cashier celebrant celebrator celebrater censor chameleon changer modifier charmer beguiler child baby chutzpanik closer clumsy_person collector aggregator color-blind_person combatant battler belligerent fighter scrapper commoner common_man common_person communicator complexifier compulsive computer_user contemplative contestant convert copycat imitator emulator ape aper counter counterterrorist coward crawler creeper creator creature wight creditor cripple dancer social_dancer dead_person dead_soul deceased_person deceased decedent departed deaf_person debaser degrader debtor debitor defecator voider shitter delayer deliverer demander dieter differentiator discriminator disentangler unraveler unraveller disputant controversialist eristic dissenter dissident protester objector contestant divider domestic_partner significant_other spousal_equivalent spouse_equivalent double image look-alike dresser dribbler driveller slobberer drooler drug_user substance_abuser user dyslectic ectomorph effecter effector Elizabethan emotional_person endomorph engineer applied_scientist technologist enjoyer enrollee entertainer ethnic experimenter expert explorer adventurer extrovert extravert face faddist faller fastener female female_person fiduciary first-rater follower free_agent free_spirit freewheeler friend fugitive runaway fleer gainer weight_gainer gainer gambler gatekeeper gatherer Gemini Twin gentile good_guy good_person granter greeter saluter welcomer grinner groaner grunter guesser handicapped_person hater heterosexual heterosexual_person straight_person straight homosexual homophile homo gay homunculus hope hoper huddler hugger immune individualist inhabitant habitant dweller denizen indweller innocent inexperienced_person insured insured_person intellectual intellect interpreter introvert Jat Jew Hebrew Israelite jewel gem jumper junior juvenile juvenile_person killer slayer kink kneeler knocker knower apprehender large_person Latin laugher leader learner scholar assimilator left-hander lefty southpaw Leo Lion Libra Balance life lightning_rod linguist polyglot literate literate_person liver longer thirster yearner loose_cannon loved_one lover machine mailer malcontent male male_person man man_jack manipulator married masturbator onanist measurer mesomorph mestizo ladino middlebrow miracle_man miracle_worker misogamist mixed-blood modern money_handler money_dealer monolingual mother_hen mouse mutilator maimer mangler namer namesake national subject native indigen indigene aborigine aboriginal native neglecter neighbor neighbour neutral nondescript nonmember nonparticipant nonpartisan nonpartizan nonperson unperson nonreligious_person nonresident nonsmoker nonworker nude nude_person nurser occultist optimist orphan ostrich ouster ejector outcaste outdoorsman owner possessor pamperer spoiler coddler mollycoddler pansexual pardoner forgiver excuser partner party passer peer equal match compeer perceiver percipient observer beholder percher person_of_color person_of_colour personage personification perspirer sweater philosopher picker chooser selector Pisces Fish pisser urinator planner contriver deviser player posturer powderer precursor forerunner preserver primitive primitive_person propositus public_relations_person pursuer pussycat quarter quitter radical realist rectifier redhead redheader red-header carrottop registrant relative relation reliever allayer comforter religious_person repeater rescuer recoverer saver rester restrainer controller revenant rich_person wealthy_person have right-hander right_hander righthander riser romper roundhead ruler swayer rusher Sagittarius Archer scientist Scorpio Scorpion scratcher second-rater mediocrity seeder cloud_seeder seeker searcher quester segregate self sensualist sentimentalist romanticist sex_object sex_symbol shaker mover_and_shaker showman signer signatory simpleton simple six-footer skidder slider slipper Slav slave slave sleepyhead sloucher small_person smasher smiler sneezer sniffer sniffler sniveler snuffer snuffler socializer socialiser sort sounding_board sphinx spitter expectorator sport sprawler spurner squinter squint-eye stifler smotherer stigmatic stigmatist stooper stranger struggler subject case guinea_pig supernumerary surrenderer yielder survivalist survivor suspect tagger tagger tapper Taurus Bull tempter termer terror scourge threat testator testate thin_person skin_and_bones scrag third-rater thrower tiger totemist toucher transfer transferee transsexual transexual transvestite cross-dresser traveler traveller trier attempter essayer turner tyrant undoer opener unfastener untier unfortunate unfortunate_person unskilled_person unwelcome_person persona_non_grata user vanisher victim dupe Victorian Virgo Virgin visionary visually_impaired_person waiter waker walk-in wanter needer ward warrior watcher weakling doormat wuss weasel White White_person Caucasian wiggler wriggler squirmer winker withholder witness worker worldling yawner conserve husband economize economise record enter put_down rescue deliver scrimp stint skimp hoard stash cache lay_away hive_up squirrel_away favor favour tighten_one's_belt overwrite vitamin_A1 retinol vitamin_A2 dehydroretinol abator abjurer abomination abstainer abstinent nondrinker achiever winner success succeeder acquaintance friend acquirer active actor doer worker adjudicator admirer adoptee adult grownup adventurer venturer adversary antagonist opponent opposer resister advisee advocate advocator proponent exponent affiant African agnostic doubter amateur Amerindian Native_American ancient anomaly unusual_person anti-American anti applicant applier appointee appointment appreciator apprehender Aquarius Water_Bearer archaist Aries Ram arrogator assessee asthmatic authority autodidact baby_boomer boomer baby_buster buster bad_guy bad_person baldhead baldpate baldy balker baulker noncompliant bather beard bedfellow bereaved bereaved_person best topper birth biter Black Black_person blackamoor Negro Negroid blogger blond blonde bluecoat bodybuilder muscle_builder muscle-builder musclebuilder muscleman bomber brunet brunette bullfighter toreador buster Cancer Crab candidate prospect capitalist Capricorn Goat captor capturer case cashier celebrant celebrator celebrater censor chameleon changer modifier charmer beguiler child baby chutzpanik closer clumsy_person collector aggregator color-blind_person combatant battler belligerent fighter scrapper commoner common_man common_person communicator complexifier compulsive computer_user contemplative contestant convert copycat imitator emulator ape aper counter counterterrorist coward crawler creeper creator creature wight creditor cripple dancer social_dancer dead_person dead_soul deceased_person deceased decedent departed deaf_person debaser degrader debtor debitor defecator voider shitter delayer deliverer demander dieter differentiator discriminator disentangler unraveler unraveller disputant controversialist eristic dissenter dissident protester objector contestant divider domestic_partner significant_other spousal_equivalent spouse_equivalent double image look-alike dresser dribbler driveller slobberer drooler drug_user substance_abuser user dyslectic ectomorph effecter effector Elizabethan emotional_person endomorph engineer applied_scientist technologist enjoyer enrollee entertainer ethnic experimenter expert explorer adventurer extrovert extravert face faddist faller fastener female female_person fiduciary first-rater follower free_agent free_spirit freewheeler friend fugitive runaway fleer gainer weight_gainer gainer gambler gatekeeper gatherer Gemini Twin gentile good_guy good_person granter greeter saluter welcomer grinner groaner grunter guesser handicapped_person hater heterosexual heterosexual_person straight_person straight homosexual homophile homo gay homunculus hope hoper huddler hugger immune individualist inhabitant habitant dweller denizen indweller innocent inexperienced_person insured insured_person intellectual intellect interpreter introvert Jat Jew Hebrew Israelite jewel gem jumper junior juvenile juvenile_person killer slayer kink kneeler knocker knower apprehender large_person Latin laugher leader learner scholar assimilator left-hander lefty southpaw Leo Lion Libra Balance life lightning_rod linguist polyglot literate literate_person liver longer thirster yearner loose_cannon loved_one lover machine mailer malcontent male male_person man man_jack manipulator married masturbator onanist measurer mesomorph mestizo ladino middlebrow miracle_man miracle_worker misogamist mixed-blood modern money_handler money_dealer monolingual mother_hen mouse mutilator maimer mangler namer namesake national subject native indigen indigene aborigine aboriginal native neglecter neighbor neighbour neutral nondescript nonmember nonparticipant nonpartisan nonpartizan nonperson unperson nonreligious_person nonresident nonsmoker nonworker nude nude_person nurser occultist optimist orphan ostrich ouster ejector outcaste outdoorsman owner possessor pamperer spoiler coddler mollycoddler pansexual pardoner forgiver excuser partner party passer peer equal match compeer perceiver percipient observer beholder percher person_of_color person_of_colour personage personification perspirer sweater philosopher picker chooser selector Pisces Fish pisser urinator planner contriver deviser player posturer powderer precursor forerunner preserver primitive primitive_person propositus public_relations_person pursuer pussycat quarter quitter radical realist rectifier redhead redheader red-header carrottop registrant relative relation reliever allayer comforter religious_person repeater rescuer recoverer saver rester restrainer controller revenant rich_person wealthy_person have right-hander right_hander righthander riser romper roundhead ruler swayer rusher Sagittarius Archer scientist Scorpio Scorpion scratcher second-rater mediocrity seeder cloud_seeder seeker searcher quester segregate self sensualist sentimentalist romanticist sex_object sex_symbol shaker mover_and_shaker showman signer signatory simpleton simple six-footer skidder slider slipper Slav slave slave sleepyhead sloucher small_person smasher smiler sneezer sniffer sniffler sniveler snuffer snuffler socializer socialiser sort sounding_board sphinx spitter expectorator sport sprawler spurner squinter squint-eye stifler smotherer stigmatic stigmatist stooper stranger struggler subject case guinea_pig supernumerary surrenderer yielder survivalist survivor suspect tagger tagger tapper Taurus Bull tempter termer terror scourge threat testator testate thin_person skin_and_bones scrag third-rater thrower tiger totemist toucher transfer transferee transsexual transexual transvestite cross-dresser traveler traveller trier attempter essayer turner tyrant undoer opener unfastener untier unfortunate unfortunate_person unskilled_person unwelcome_person persona_non_grata user vanisher victim dupe Victorian Virgo Virgin visionary visually_impaired_person waiter waker walk-in wanter needer ward warrior watcher weakling doormat wuss weasel White White_person Caucasian wiggler wriggler squirmer winker withholder witness worker worldling yawner first_person second_person third_person\n",
      "\n",
      "abound accept take account account_for act answer appear seem bake broil balance be_well beat begin begin start belong belong belong belong breathe buy clean cohere come_in_for come_in_handy compact pack compare confuse throw fox befuddle fuddle bedevil confound discombobulate connect consist consist comprise contain contain take hold continue cost be count matter weigh count cover cut cut_across deck adorn decorate grace embellish beautify depend deserve merit disagree disaccord discord distribute diverge draw end terminate fall come fall feel figure enter fit gape yawn yaw go gravitate hail come hang head head_up hold hoodoo hum buzz seethe impend incarnate body_forth embody substantiate iridesce jumble mingle kill lend let_go lie litter loiter lounge footle lollygag loaf lallygag hang_around mess_about tarry linger lurk mill_about mill_around look appear seem look lubricate make make_sense add_up measure mope moon_around moon_about object osculate owe pay point press promise prove turn_out turn_up put_out rage range run rank rate recognize relate interrelate remain represent rest retard run go run_into encounter rut seem seethe boil sell sell sell shine shine sparkle scintillate coruscate specify define delineate delimit delimitate squat stagnate stagnate stand stand stand_by stick_by stick adhere stay remain rest stay stay_on continue remain stick stink subtend delimit suck suffer hurt suffer suit swim swim drown swing tend be_given lean incline run test total number add_up come amount translate transplant trim underlie want need require wash wind twist curve work attend go_to belong go center_on come cover continue extend extend poke_out reach_out face follow go lead inhabit lie lie rest occupy fill populate dwell live inhabit reach extend_to touch run go pass lead extend sit sit_around sit stand_back keep_one's_eyes_off keep_one's_distance keep_one's_hands_off stay_away straddle stretch stretch_along coexist come distribute dwell consist lie lie_in dwell inhabit endanger jeopardize jeopardise menace threaten imperil peril flow indwell kick_around knock_about kick_about preexist prevail hold obtain equate correspond match fit correspond check jibe gibe tally agree represent stand_for correspond translate compose fall_into fall_under form constitute make make present pose range straddle supplement cox vet body personify exemplify represent set_back knock_back put_back\n",
      "blow_out catch light_up dehisce\n",
      "dynamite fulminate crump erupt belch extravasate go_off\n",
      "[('A', 'DT'), ('person', 'NN'), ('who', 'WP'), ('creates', 'VBZ'), ('something', 'NN'), ('new', 'JJ'), ('that', 'WDT'), ('has', 'VBZ'), ('never', 'RB'), ('been', 'VBN'), ('made', 'VBN'), ('before', 'IN')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Someone', 'NN'), ('you', 'PRP'), ('admire', 'VBP'), ('because', 'IN'), ('they', 'PRP'), ('have', 'VBP'), ('done', 'VBN'), ('an', 'DT'), ('action', 'NN'), ('that', 'WDT'), ('is', 'VBZ'), ('brave', 'VB'), ('or', 'CC'), ('new', 'JJ'), ('or', 'CC'), ('good', 'JJ')]\n",
      "[('Describes', 'NNP'), ('something', 'NN'), ('that', 'WDT'), ('is', 'VBZ'), ('very', 'RB'), ('difficult', 'JJ'), ('or', 'CC'), ('can', 'MD'), ('not', 'RB'), ('happen', 'VB')]\n",
      "[('It', 'PRP'), ('means', 'VBZ'), ('to', 'TO'), ('explode', 'VB'), ('or', 'CC'), ('to', 'TO'), ('burst', 'VB'), ('out', 'RP'), ('with', 'IN'), ('force', 'NN')]\n",
      "[('A', 'DT'), ('force', 'NN'), ('pushing', 'VBG'), ('against', 'IN'), ('something', 'NN'), ('.', '.')]\n",
      "[('To', 'TO'), ('study', 'VB'), ('something', 'NN'), ('closely', 'RB'), ('and', 'CC'), ('carefully', 'RB')]\n",
      "[('Describes', 'NNP'), ('something', 'NN'), ('stiff', 'NN'), ('or', 'CC'), ('hard', 'JJ'), ('to', 'TO'), ('bend', 'VB')]\n",
      "[('It', 'PRP'), ('means', 'VBZ'), ('to', 'TO'), ('find', 'VB'), ('the', 'DT'), ('size', 'NN'), (',', ','), ('weight', 'NN'), (',', ','), ('or', 'CC'), ('amount', 'NN'), ('of', 'IN'), ('something', 'NN'), ('using', 'VBG'), ('a', 'DT'), ('tool', 'NN'), ('.', '.')]\n",
      "[('Describes', 'NNP'), ('something', 'NN'), ('that', 'WDT'), ('is', 'VBZ'), ('close', 'RB'), ('or', 'CC'), ('nearby', 'RB'), ('.', '.')]\n",
      "[('To', 'TO'), ('take', 'VB'), ('care', 'NN'), ('of', 'IN'), ('or', 'CC'), ('make', 'VB'), ('decisions', 'NNS'), ('about', 'IN'), ('something', 'NN'), ('.', '.')]\n",
      "[('A', 'DT'), ('special', 'JJ'), ('quality', 'NN'), ('that', 'WDT'), ('makes', 'VBZ'), ('something', 'NN'), ('or', 'CC'), ('someone', 'NN'), ('different', 'JJ'), ('from', 'IN'), ('others', 'NNS'), ('.', '.')]\n",
      "[('To', 'TO'), ('act', 'VB'), ('or', 'CC'), ('speak', 'VB'), ('for', 'IN'), ('someone', 'NN'), ('else', 'RB'), ('officially', 'RB'), ('.', '.')]\n",
      "[('To', 'TO'), ('change', 'VB'), ('according', 'VBG'), ('to', 'TO'), ('the', 'DT'), ('conditions', 'NNS'), ('on', 'IN'), ('the', 'DT'), ('environment', 'NN'), ('.', '.')]\n",
      "[('Something', 'VBG'), ('that', 'WDT'), ('can', 'MD'), ('be', 'VB'), ('used', 'VBN'), ('when', 'WRB'), ('needed', 'VBN')]\n",
      "[('The', 'DT'), ('movement', 'NN'), ('of', 'IN'), ('earth', 'JJ'), ('materials', 'NNS'), ('from', 'IN'), ('one', 'CD'), ('place', 'NN'), ('to', 'TO'), ('another', 'DT')]\n",
      "[('When', 'WRB'), ('an', 'DT'), ('animal', 'JJ'), ('moves', 'NNS'), ('from', 'IN'), ('one', 'CD'), ('place', 'NN'), ('to', 'TO'), ('another', 'DT'), (',', ','), ('usually', 'RB'), ('following', 'VBG'), ('the', 'DT'), ('seasons', 'NNS'), ('.', '.'), ('To', 'TO'), ('go', 'VB'), ('from', 'IN'), ('one', 'CD'), ('country', 'NN'), (',', ','), ('region', 'NN'), (',', ','), ('or', 'CC'), ('place', 'NN'), ('to', 'TO'), ('another', 'DT'), ('.', '.')]\n",
      "[('To', 'TO'), ('change', 'VB'), ('someone', 'NN'), (\"'s\", 'POS'), ('behavior', 'NN'), (',', ','), ('opinion', 'NN'), (',', ','), ('or', 'CC'), ('action', 'NN')]\n",
      "[('Means', 'VBZ'), ('the', 'DT'), ('state', 'NN'), ('of', 'IN'), ('something', 'NN'), ('or', 'CC'), ('someone', 'NN'), ('.', '.')]\n",
      "[('A', 'DT'), ('person', 'NN'), ('who', 'WP'), ('studies', 'NNS'), ('how', 'WRB'), ('the', 'DT'), ('world', 'NN'), ('works', 'VBZ'), ('through', 'IN'), ('observations', 'NNS'), ('and', 'CC'), ('experiments', 'NNS'), ('.', '.')]\n",
      "[('The', 'DT'), ('strong', 'JJ'), ('influence', 'NN'), ('of', 'IN'), ('a', 'DT'), ('person', 'NN'), (',', ','), ('a', 'DT'), ('thing', 'NN'), (',', ','), ('or', 'CC'), ('an', 'DT'), ('action', 'NN'), ('on', 'IN'), ('something', 'NN'), ('else', 'RB')]\n",
      "[('How', 'WRB'), ('we', 'PRP'), ('learn', 'VBP'), ('about', 'IN'), ('the', 'DT'), ('world', 'NN'), ('and', 'CC'), ('how', 'WRB'), ('we', 'PRP'), ('learn', 'VBP'), ('new', 'JJ'), ('things', 'NNS')]\n",
      "[('A', 'DT'), ('person', 'NN'), ('who', 'WP'), ('practices', 'NNS'), ('or', 'CC'), ('studies', 'NNS'), ('law', 'NN')]\n",
      "[('The', 'DT'), ('idea', 'NN'), ('of', 'IN'), ('treating', 'VBG'), ('some', 'DT'), ('people', 'NNS'), ('better', 'JJR'), ('than', 'IN'), ('others', 'NNS'), ('without', 'IN'), ('a', 'DT'), ('fair', 'JJ'), ('reason', 'NN'), ('.', '.')]\n",
      "a person who create something new that have never be make before\n",
      "someone you admire because they have do an action that be brave or new or good\n",
      "describe something that be very difficult or can not happen\n",
      "it mean to explode or to burst out with force\n",
      "a force push against something .\n",
      "to study something closely and carefully\n",
      "describe something stiff or hard to bend\n",
      "it mean to find the size , weight , or amount of something use a tool .\n",
      "describe something that be close or nearby .\n",
      "to take care of or make decision about something .\n",
      "a special quality that make something or someone different from others .\n",
      "to act or speak for someone else officially .\n",
      "to change accord to the condition on the environment .\n",
      "something that can be use when need\n",
      "the movement of earth material from one place to another\n",
      "when an animal move from one place to another , usually follow the season . to go from one country , region , or place to another .\n",
      "to change someone 's behavior , opinion , or action\n",
      "mean the state of something or someone .\n",
      "a person who study how the world work through observation and experiment .\n",
      "the strong influence of a person , a thing , or an action on something else\n",
      "how we learn about the world and how we learn new thing\n",
      "a person who practice or study law\n",
      "the idea of treat some people better than others without a fair reason .\n"
     ]
    }
   ],
   "source": [
    "from basic_nlp import fex_basic_nlp\n",
    "\n",
    "pipeline=['pos', 'lemma', 'synset', 'hype', 'hypo']\n",
    "\n",
    "bnlqd = fex_basic_nlp(data_file, data_dir)\n",
    "bnlqd.nlp_run(pipeline[0])\n",
    "bnlqd.nlp_run(pipeline[1])\n",
    "bnlqd.df_ac_lemma.to_csv(data_dir + 'Lemma-' + data_file, encoding= 'latin1')\n",
    "bnlqd.nlp_run(pipeline[2])\n",
    "bnlqd.df_ac_synset.to_csv(data_dir + 'Synset-' + data_file , encoding= 'latin1')\n",
    "bnlqd.nlp_run(pipeline[3])\n",
    "bnlqd.df_ac_hypernyms.to_csv(data_dir + 'Hypernyms-' + data_file, encoding= 'latin1')\n",
    "bnlqd.nlp_run(pipeline[4])\n",
    "bnlqd.df_ac_hyponyms.to_csv(data_dir + 'Hyponyms-' + data_file, encoding= 'latin1')\n",
    "\n",
    "bnlpd = fex_basic_nlp(def_file, data_dir, 'Definition')\n",
    "bnlpd.nlp_run(pipeline[0])\n",
    "bnlpd.df_ac_pos.to_csv(data_dir + 'POS-P-' + data_file, encoding= 'latin1')\n",
    "bnlpd.nlp_run(pipeline[1])\n",
    "bnlpd.df_ac_lemma.to_csv(data_dir + 'Lemma-P-' + data_file, encoding= 'latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[('to', 'invent'), ('invent', 'stuff')]\n",
      "\n",
      "[('someone', 'that'), ('that', 'save'), ('save', 'a'), ('a', 'person')]\n",
      "\n",
      "[('something', 'that'), ('that', 'be'), ('be', 'not'), ('not', 'possible')]\n",
      "[('to', 'erupt')]\n",
      "[('when', 'something'), ('something', 'explode')]\n",
      "\n",
      "[('to', 'invent', 'stuff')]\n",
      "\n",
      "[('someone', 'that', 'save'), ('that', 'save', 'a'), ('save', 'a', 'person')]\n",
      "\n",
      "[('something', 'that', 'be'), ('that', 'be', 'not'), ('be', 'not', 'possible')]\n",
      "\n",
      "[('when', 'something', 'explode')]\n"
     ]
    }
   ],
   "source": [
    "from bi_trigram import bi_trigram\n",
    "\n",
    "btgqd = bi_trigram(data_file, data_dir)\n",
    "btgqd.nlp_run(r'bigram')\n",
    "btgqd.nlp_run(r'trigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove Stop Word:  and\n",
      "Remove Stop Word:  or\n",
      "Question:2001-Inventor\n",
      "KNOWN: inventor\n",
      "TERM COUNT: 1\n",
      "KNOWN: invent\n",
      "KNOWN: stuff\n",
      "TERM COUNT: 2\n",
      "Question:2001-Hero\n",
      "KNOWN: hero\n",
      "TERM COUNT: 1\n",
      "KNOWN: person\n",
      "KNOWN: save\n",
      "KNOWN: someone\n",
      "KNOWN: that\n",
      "TERM COUNT: 4\n",
      "Question:2001-Impossible\n",
      "KNOWN: impossible\n",
      "TERM COUNT: 1\n",
      "KNOWN: not\n",
      "KNOWN: possible\n",
      "KNOWN: something\n",
      "KNOWN: that\n",
      "TERM COUNT: 4\n",
      "Question:2001-To erupt\n",
      "KNOWN: erupt\n",
      "TERM COUNT: 1\n",
      "KNOWN: explode\n",
      "KNOWN: something\n",
      "KNOWN: when\n",
      "TERM COUNT: 3\n"
     ]
    }
   ],
   "source": [
    "from oanc_lemma_frequency import odi_oanc_lemma_frequency\n",
    "\n",
    "stop_words = ['a', 'be', 'to', 'and', 'or']\n",
    "stop_words_d = remove_non_extracted_stop_word(bnlqd.df_ac_lemma, stop_words)\n",
    "\n",
    "oanc_shelve = r'../../plimac3/Resource/OANC/ANC-all-lemma-04262014.db'\n",
    "oalqd = odi_oanc_lemma_frequency(data_file, oanc_shelve, None, data_dir, stop_words_d)    \n",
    "oalqd.oanc_lemma_frequency('Lemma-' + data_file, r'Student_Question_Index', r'Pre_Col_Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:2001-Inventor\n",
      "Passage:QP14001\n",
      "Question:2001-Hero\n",
      "Passage:QP14002\n",
      "Question:2001-Impossible\n",
      "Passage:QP14003\n",
      "Question:2001-To erupt\n",
      "Passage:QP14004\n",
      "Question:2001-Inventor\n",
      "Passage:QP14001\n",
      "Question:2001-Hero\n",
      "Passage:QP14002\n",
      "Question:2001-Impossible\n",
      "Passage:QP14003\n",
      "Question:2001-To erupt\n",
      "Passage:QP14004\n",
      "Question:2001-Inventor\n",
      "Passage:QP14001\n",
      "Question:2001-Hero\n",
      "Passage:QP14002\n",
      "Question:2001-Impossible\n",
      "Passage:QP14003\n",
      "Question:2001-To erupt\n",
      "Passage:QP14004\n",
      "Question:2001-Inventor\n",
      "Passage:QP14001\n",
      "Question:2001-Hero\n",
      "Passage:QP14002\n",
      "Question:2001-Impossible\n",
      "Passage:QP14003\n",
      "Question:2001-To erupt\n",
      "Passage:QP14004\n"
     ]
    }
   ],
   "source": [
    "from overlapping import odi_overlapping\n",
    "\n",
    "stop_words_hy = ['be']\n",
    "stop_words_hy_d = remove_non_extracted_stop_word(bnlqd.df_ac_lemma, stop_words_hy)\n",
    "\n",
    "ovlqd = odi_overlapping(data_file, r'Questin_ID_Definition.csv', data_dir, stop_words_d)\n",
    "ovlqd.count_overlapping('Lemma-' + data_file, r'Student_Question_Index',\n",
    "                     r'Pre_Col_Name', r'Question_ID', r'Question_ID_Sec',\n",
    "                     'Lemma-P-' + data_file, r'Question_ID', r'Question_ID_Sec')\n",
    "ovlqd.count_overlapping_synset('Synset-' + data_file)\n",
    "ovlqd.count_overlapping_hypernyms('Hypernyms-' + data_file, stop_words_hy_d)\n",
    "ovlqd.count_overlapping_hyponyms('Hyponyms-' + data_file, stop_words_hy_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ac_bi_trigram_pmi_distribution as gpmd\n",
    "\n",
    "def bi_trigram_pmi_distribution(csv_file_pmi_sum_t, data_dir, num_clm_in_q, df_ac_gram, \n",
    "                                gram = r'bigram', pmi_frq_min = 2, decimal_places = 4):\n",
    "    df_ac_pmi_sum_t = pd.read_csv(data_dir + csv_file_pmi_sum_t, encoding= 'latin1')\n",
    "    if gram == r'bigram':\n",
    "        sum_clm = 'Bigram_sum'\n",
    "    else: sum_clm = 'Trigram_sum'\n",
    "    \n",
    "    df_ac_pmi_gram = df_ac_pmi_sum_t[df_ac_pmi_sum_t[sum_clm] >= pmi_frq_min]\n",
    "    df_ac_pmi_dist_gram = gpmd.ac_bi_trigram_pmi_distribution(df_ac_gram,\n",
    "                    num_clm_in_q + 1, df_ac_pmi_gram, gram, decimal_places)\n",
    "    return df_ac_pmi_dist_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student_Question_Index</th>\n",
       "      <th>Student Data-Group</th>\n",
       "      <th>Student Data-School ID</th>\n",
       "      <th>Student Data-Teacher ID</th>\n",
       "      <th>Student Data-Teacher Last</th>\n",
       "      <th>Student Data-Student ID</th>\n",
       "      <th>Student Data-Treatment</th>\n",
       "      <th>Definition-Score</th>\n",
       "      <th>Definition-Language</th>\n",
       "      <th>Question_ID</th>\n",
       "      <th>Question_ID_Sec</th>\n",
       "      <th>Definition</th>\n",
       "      <th>Pre_Col_Name</th>\n",
       "      <th>Content</th>\n",
       "      <th>Cntnt_Bigram</th>\n",
       "      <th>PMI_Bigram_Mean</th>\n",
       "      <th>PMI_Bigram_SD</th>\n",
       "      <th>PMI_Bigram_Max</th>\n",
       "      <th>PMI_Bigram_Min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AC_Doc_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-Inventor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>101901</td>\n",
       "      <td>Burrus</td>\n",
       "      <td>101046</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>QP14001</td>\n",
       "      <td>QP14001</td>\n",
       "      <td>A person who creates something new that has ne...</td>\n",
       "      <td>Definition-Question</td>\n",
       "      <td>Inventor</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-Inventor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>101901</td>\n",
       "      <td>Burrus</td>\n",
       "      <td>101046</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>QP14001</td>\n",
       "      <td>QP14001</td>\n",
       "      <td>A person who creates something new that has ne...</td>\n",
       "      <td>Definition-Answer</td>\n",
       "      <td>To invent stuff</td>\n",
       "      <td>[('to', 'invent'), ('invent', 'stuff')]</td>\n",
       "      <td>1.8037</td>\n",
       "      <td>2.5508</td>\n",
       "      <td>3.6074</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-Hero</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>101901</td>\n",
       "      <td>Burrus</td>\n",
       "      <td>101046</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>QP14002</td>\n",
       "      <td>QP14002</td>\n",
       "      <td>Someone  you  admire  because  they  have  don...</td>\n",
       "      <td>Definition-Question</td>\n",
       "      <td>Hero</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-Hero</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>101901</td>\n",
       "      <td>Burrus</td>\n",
       "      <td>101046</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>QP14002</td>\n",
       "      <td>QP14002</td>\n",
       "      <td>Someone  you  admire  because  they  have  don...</td>\n",
       "      <td>Definition-Answer</td>\n",
       "      <td>Someone that saves a person</td>\n",
       "      <td>[('someone', 'that'), ('that', 'save'), ('save...</td>\n",
       "      <td>2.7124</td>\n",
       "      <td>1.5184</td>\n",
       "      <td>4.5728</td>\n",
       "      <td>0.8593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-Impossible</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>101901</td>\n",
       "      <td>Burrus</td>\n",
       "      <td>101046</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>QP14003</td>\n",
       "      <td>QP14003</td>\n",
       "      <td>Describes something that is very difficult or ...</td>\n",
       "      <td>Definition-Question</td>\n",
       "      <td>Impossible</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2001-Impossible</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>101901</td>\n",
       "      <td>Burrus</td>\n",
       "      <td>101046</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>QP14003</td>\n",
       "      <td>QP14003</td>\n",
       "      <td>Describes something that is very difficult or ...</td>\n",
       "      <td>Definition-Answer</td>\n",
       "      <td>Something that is not possible</td>\n",
       "      <td>[('something', 'that'), ('that', 'be'), ('be',...</td>\n",
       "      <td>2.7432</td>\n",
       "      <td>3.2980</td>\n",
       "      <td>7.4148</td>\n",
       "      <td>-0.0304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2001-To erupt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>101901</td>\n",
       "      <td>Burrus</td>\n",
       "      <td>101046</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>QP14004</td>\n",
       "      <td>QP14004</td>\n",
       "      <td>It means to explode or to burst out with force</td>\n",
       "      <td>Definition-Question</td>\n",
       "      <td>To erupt</td>\n",
       "      <td>[('to', 'erupt')]</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2001-To erupt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>101901</td>\n",
       "      <td>Burrus</td>\n",
       "      <td>101046</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>QP14004</td>\n",
       "      <td>QP14004</td>\n",
       "      <td>It means to explode or to burst out with force</td>\n",
       "      <td>Definition-Answer</td>\n",
       "      <td>When something explodes</td>\n",
       "      <td>[('when', 'something'), ('something', 'explode')]</td>\n",
       "      <td>1.4264</td>\n",
       "      <td>0.8513</td>\n",
       "      <td>2.0283</td>\n",
       "      <td>0.8244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Student_Question_Index  Student Data-Group  Student Data-School ID  \\\n",
       "AC_Doc_ID                                                                      \n",
       "0                  2001-Inventor                 NaN                     101   \n",
       "1                  2001-Inventor                 NaN                     101   \n",
       "2                      2001-Hero                 NaN                     101   \n",
       "3                      2001-Hero                 NaN                     101   \n",
       "4                2001-Impossible                 NaN                     101   \n",
       "5                2001-Impossible                 NaN                     101   \n",
       "6                  2001-To erupt                 NaN                     101   \n",
       "7                  2001-To erupt                 NaN                     101   \n",
       "\n",
       "           Student Data-Teacher ID Student Data-Teacher Last  \\\n",
       "AC_Doc_ID                                                      \n",
       "0                           101901                    Burrus   \n",
       "1                           101901                    Burrus   \n",
       "2                           101901                    Burrus   \n",
       "3                           101901                    Burrus   \n",
       "4                           101901                    Burrus   \n",
       "5                           101901                    Burrus   \n",
       "6                           101901                    Burrus   \n",
       "7                           101901                    Burrus   \n",
       "\n",
       "           Student Data-Student ID  Student Data-Treatment  Definition-Score  \\\n",
       "AC_Doc_ID                                                                      \n",
       "0                           101046                       0                 0   \n",
       "1                           101046                       0                 0   \n",
       "2                           101046                       0                 1   \n",
       "3                           101046                       0                 1   \n",
       "4                           101046                       0                 1   \n",
       "5                           101046                       0                 1   \n",
       "6                           101046                       0                 2   \n",
       "7                           101046                       0                 2   \n",
       "\n",
       "           Definition-Language Question_ID Question_ID_Sec  \\\n",
       "AC_Doc_ID                                                    \n",
       "0                            1     QP14001         QP14001   \n",
       "1                            1     QP14001         QP14001   \n",
       "2                            1     QP14002         QP14002   \n",
       "3                            1     QP14002         QP14002   \n",
       "4                            1     QP14003         QP14003   \n",
       "5                            1     QP14003         QP14003   \n",
       "6                            1     QP14004         QP14004   \n",
       "7                            1     QP14004         QP14004   \n",
       "\n",
       "                                                  Definition  \\\n",
       "AC_Doc_ID                                                      \n",
       "0          A person who creates something new that has ne...   \n",
       "1          A person who creates something new that has ne...   \n",
       "2          Someone  you  admire  because  they  have  don...   \n",
       "3          Someone  you  admire  because  they  have  don...   \n",
       "4          Describes something that is very difficult or ...   \n",
       "5          Describes something that is very difficult or ...   \n",
       "6             It means to explode or to burst out with force   \n",
       "7             It means to explode or to burst out with force   \n",
       "\n",
       "                  Pre_Col_Name                         Content  \\\n",
       "AC_Doc_ID                                                        \n",
       "0          Definition-Question                        Inventor   \n",
       "1            Definition-Answer                 To invent stuff   \n",
       "2          Definition-Question                            Hero   \n",
       "3            Definition-Answer     Someone that saves a person   \n",
       "4          Definition-Question                      Impossible   \n",
       "5            Definition-Answer  Something that is not possible   \n",
       "6          Definition-Question                        To erupt   \n",
       "7            Definition-Answer         When something explodes   \n",
       "\n",
       "                                                Cntnt_Bigram  PMI_Bigram_Mean  \\\n",
       "AC_Doc_ID                                                                       \n",
       "0                                                                         NaN   \n",
       "1                    [('to', 'invent'), ('invent', 'stuff')]           1.8037   \n",
       "2                                                                         NaN   \n",
       "3          [('someone', 'that'), ('that', 'save'), ('save...           2.7124   \n",
       "4                                                                         NaN   \n",
       "5          [('something', 'that'), ('that', 'be'), ('be',...           2.7432   \n",
       "6                                          [('to', 'erupt')]           0.0000   \n",
       "7          [('when', 'something'), ('something', 'explode')]           1.4264   \n",
       "\n",
       "           PMI_Bigram_SD  PMI_Bigram_Max  PMI_Bigram_Min  \n",
       "AC_Doc_ID                                                 \n",
       "0                    NaN             NaN             NaN  \n",
       "1                 2.5508          3.6074          0.0000  \n",
       "2                    NaN             NaN             NaN  \n",
       "3                 1.5184          4.5728          0.8593  \n",
       "4                    NaN             NaN             NaN  \n",
       "5                 3.2980          7.4148         -0.0304  \n",
       "6                    NaN          0.0000          0.0000  \n",
       "7                 0.8513          2.0283          0.8244  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ac_pmi_dist_bigram = bi_trigram_pmi_distribution('PMI-Sum-T-Bigram-Def-PRE.csv', data_dir, \n",
    "                                                    bnlqd.num_clm_in, btgqd.df_ac_bigram, r'bigram')\n",
    "df_ac_pmi_dist_bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student_Question_Index</th>\n",
       "      <th>Student Data-Group</th>\n",
       "      <th>Student Data-School ID</th>\n",
       "      <th>Student Data-Teacher ID</th>\n",
       "      <th>Student Data-Teacher Last</th>\n",
       "      <th>Student Data-Student ID</th>\n",
       "      <th>Student Data-Treatment</th>\n",
       "      <th>Definition-Score</th>\n",
       "      <th>Definition-Language</th>\n",
       "      <th>Question_ID</th>\n",
       "      <th>Question_ID_Sec</th>\n",
       "      <th>Definition</th>\n",
       "      <th>Pre_Col_Name</th>\n",
       "      <th>Content</th>\n",
       "      <th>Cntnt_Trigram</th>\n",
       "      <th>PMI_Trigram_Mean</th>\n",
       "      <th>PMI_Trigram_SD</th>\n",
       "      <th>PMI_Trigram_Max</th>\n",
       "      <th>PMI_Trigram_Min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AC_Doc_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-Inventor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>101901</td>\n",
       "      <td>Burrus</td>\n",
       "      <td>101046</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>QP14001</td>\n",
       "      <td>QP14001</td>\n",
       "      <td>A person who creates something new that has ne...</td>\n",
       "      <td>Definition-Question</td>\n",
       "      <td>Inventor</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-Inventor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>101901</td>\n",
       "      <td>Burrus</td>\n",
       "      <td>101046</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>QP14001</td>\n",
       "      <td>QP14001</td>\n",
       "      <td>A person who creates something new that has ne...</td>\n",
       "      <td>Definition-Answer</td>\n",
       "      <td>To invent stuff</td>\n",
       "      <td>[('to', 'invent', 'stuff')]</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-Hero</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>101901</td>\n",
       "      <td>Burrus</td>\n",
       "      <td>101046</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>QP14002</td>\n",
       "      <td>QP14002</td>\n",
       "      <td>Someone  you  admire  because  they  have  don...</td>\n",
       "      <td>Definition-Question</td>\n",
       "      <td>Hero</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-Hero</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>101901</td>\n",
       "      <td>Burrus</td>\n",
       "      <td>101046</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>QP14002</td>\n",
       "      <td>QP14002</td>\n",
       "      <td>Someone  you  admire  because  they  have  don...</td>\n",
       "      <td>Definition-Answer</td>\n",
       "      <td>Someone that saves a person</td>\n",
       "      <td>[('someone', 'that', 'save'), ('that', 'save',...</td>\n",
       "      <td>4.3525</td>\n",
       "      <td>3.7824</td>\n",
       "      <td>6.8432</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-Impossible</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>101901</td>\n",
       "      <td>Burrus</td>\n",
       "      <td>101046</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>QP14003</td>\n",
       "      <td>QP14003</td>\n",
       "      <td>Describes something that is very difficult or ...</td>\n",
       "      <td>Definition-Question</td>\n",
       "      <td>Impossible</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2001-Impossible</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>101901</td>\n",
       "      <td>Burrus</td>\n",
       "      <td>101046</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>QP14003</td>\n",
       "      <td>QP14003</td>\n",
       "      <td>Describes something that is very difficult or ...</td>\n",
       "      <td>Definition-Answer</td>\n",
       "      <td>Something that is not possible</td>\n",
       "      <td>[('something', 'that', 'be'), ('that', 'be', '...</td>\n",
       "      <td>4.7636</td>\n",
       "      <td>5.7843</td>\n",
       "      <td>11.1999</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2001-To erupt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>101901</td>\n",
       "      <td>Burrus</td>\n",
       "      <td>101046</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>QP14004</td>\n",
       "      <td>QP14004</td>\n",
       "      <td>It means to explode or to burst out with force</td>\n",
       "      <td>Definition-Question</td>\n",
       "      <td>To erupt</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2001-To erupt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>101901</td>\n",
       "      <td>Burrus</td>\n",
       "      <td>101046</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>QP14004</td>\n",
       "      <td>QP14004</td>\n",
       "      <td>It means to explode or to burst out with force</td>\n",
       "      <td>Definition-Answer</td>\n",
       "      <td>When something explodes</td>\n",
       "      <td>[('when', 'something', 'explode')]</td>\n",
       "      <td>6.7824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.7824</td>\n",
       "      <td>6.7824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Student_Question_Index  Student Data-Group  Student Data-School ID  \\\n",
       "AC_Doc_ID                                                                      \n",
       "0                  2001-Inventor                 NaN                     101   \n",
       "1                  2001-Inventor                 NaN                     101   \n",
       "2                      2001-Hero                 NaN                     101   \n",
       "3                      2001-Hero                 NaN                     101   \n",
       "4                2001-Impossible                 NaN                     101   \n",
       "5                2001-Impossible                 NaN                     101   \n",
       "6                  2001-To erupt                 NaN                     101   \n",
       "7                  2001-To erupt                 NaN                     101   \n",
       "\n",
       "           Student Data-Teacher ID Student Data-Teacher Last  \\\n",
       "AC_Doc_ID                                                      \n",
       "0                           101901                    Burrus   \n",
       "1                           101901                    Burrus   \n",
       "2                           101901                    Burrus   \n",
       "3                           101901                    Burrus   \n",
       "4                           101901                    Burrus   \n",
       "5                           101901                    Burrus   \n",
       "6                           101901                    Burrus   \n",
       "7                           101901                    Burrus   \n",
       "\n",
       "           Student Data-Student ID  Student Data-Treatment  Definition-Score  \\\n",
       "AC_Doc_ID                                                                      \n",
       "0                           101046                       0                 0   \n",
       "1                           101046                       0                 0   \n",
       "2                           101046                       0                 1   \n",
       "3                           101046                       0                 1   \n",
       "4                           101046                       0                 1   \n",
       "5                           101046                       0                 1   \n",
       "6                           101046                       0                 2   \n",
       "7                           101046                       0                 2   \n",
       "\n",
       "           Definition-Language Question_ID Question_ID_Sec  \\\n",
       "AC_Doc_ID                                                    \n",
       "0                            1     QP14001         QP14001   \n",
       "1                            1     QP14001         QP14001   \n",
       "2                            1     QP14002         QP14002   \n",
       "3                            1     QP14002         QP14002   \n",
       "4                            1     QP14003         QP14003   \n",
       "5                            1     QP14003         QP14003   \n",
       "6                            1     QP14004         QP14004   \n",
       "7                            1     QP14004         QP14004   \n",
       "\n",
       "                                                  Definition  \\\n",
       "AC_Doc_ID                                                      \n",
       "0          A person who creates something new that has ne...   \n",
       "1          A person who creates something new that has ne...   \n",
       "2          Someone  you  admire  because  they  have  don...   \n",
       "3          Someone  you  admire  because  they  have  don...   \n",
       "4          Describes something that is very difficult or ...   \n",
       "5          Describes something that is very difficult or ...   \n",
       "6             It means to explode or to burst out with force   \n",
       "7             It means to explode or to burst out with force   \n",
       "\n",
       "                  Pre_Col_Name                         Content  \\\n",
       "AC_Doc_ID                                                        \n",
       "0          Definition-Question                        Inventor   \n",
       "1            Definition-Answer                 To invent stuff   \n",
       "2          Definition-Question                            Hero   \n",
       "3            Definition-Answer     Someone that saves a person   \n",
       "4          Definition-Question                      Impossible   \n",
       "5            Definition-Answer  Something that is not possible   \n",
       "6          Definition-Question                        To erupt   \n",
       "7            Definition-Answer         When something explodes   \n",
       "\n",
       "                                               Cntnt_Trigram  \\\n",
       "AC_Doc_ID                                                      \n",
       "0                                                              \n",
       "1                                [('to', 'invent', 'stuff')]   \n",
       "2                                                              \n",
       "3          [('someone', 'that', 'save'), ('that', 'save',...   \n",
       "4                                                              \n",
       "5          [('something', 'that', 'be'), ('that', 'be', '...   \n",
       "6                                                              \n",
       "7                         [('when', 'something', 'explode')]   \n",
       "\n",
       "           PMI_Trigram_Mean  PMI_Trigram_SD  PMI_Trigram_Max  PMI_Trigram_Min  \n",
       "AC_Doc_ID                                                                      \n",
       "0                       NaN             NaN              NaN              NaN  \n",
       "1                    0.0000             NaN           0.0000           0.0000  \n",
       "2                       NaN             NaN              NaN              NaN  \n",
       "3                    4.3525          3.7824           6.8432           0.0000  \n",
       "4                       NaN             NaN              NaN              NaN  \n",
       "5                    4.7636          5.7843          11.1999           0.0000  \n",
       "6                       NaN             NaN              NaN              NaN  \n",
       "7                    6.7824             NaN           6.7824           6.7824  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ac_pmi_dist_trigram = bi_trigram_pmi_distribution('PMI-Sum-T-Trigram-Def-PRE.csv', data_dir, \n",
    "                                                    bnlqd.num_clm_in, btgqd.df_ac_trigram, r'Trigram')\n",
    "df_ac_pmi_dist_trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ac_aggregate_plim as agpl\n",
    "import ac_aggregate_item_level_plim as agpi\n",
    "\n",
    "def aggregate_plim(bnlqd, oalqd, ovlqd, df_ac_pmi_dist_bigram, df_ac_pmi_dist_trigram, bnlpd,\n",
    "                         specific_count_lemmas = None, stop_words_pos = None, \n",
    "                         task_name = 'Definition', decimal_places = 4):\n",
    "    stem_identifier = task_name + '-Question'\n",
    "    option_identifier = task_name + '-Answer'\n",
    "    df_ac_lemma_buf = bnlqd.df_ac_lemma.copy()\n",
    "\n",
    "    if specific_count_lemmas is not None:\n",
    "        for x in specific_count_lemmas:\n",
    "            if not bnlqd.df_ac_lemma.columns.isin([x]).any():\n",
    "                df_ac_lemma_buf[x] = 0\n",
    "\n",
    "    df_ac_oanc_lemma_freq = oalqd.df_ac_oanc_lemma_freq_q.drop([oalqd.question_id_clm,\n",
    "                             oalqd.stem_option_name_clm], axis=1)\n",
    "    df_ac_overlapping_lemma = ovlqd.df_ac_overlapping_lemma.drop([oalqd.question_id_clm,\n",
    "                             oalqd.stem_option_name_clm], axis=1)\n",
    "    df_ac_overlapping_synset = ovlqd.df_ac_overlapping_syn_lemma.drop([oalqd.question_id_clm,\n",
    "                             oalqd.stem_option_name_clm], axis=1)\n",
    "    df_ac_overlapping_hyper = ovlqd.df_ac_overlapping_hyper_lemma.drop([oalqd.question_id_clm,\n",
    "                             oalqd.stem_option_name_clm], axis=1)\n",
    "    df_ac_overlapping_hypo = ovlqd.df_ac_overlapping_hypo_lemma.drop([oalqd.question_id_clm,\n",
    "                             oalqd.stem_option_name_clm], axis=1)\n",
    "\n",
    "    df_ac_pmi_dist_bigram = df_ac_pmi_dist_bigram.iloc[:, oalqd.num_clm_in_q:]\n",
    "    df_ac_pmi_dist_bigram['Cntnt_Bigram'] = df_ac_pmi_dist_bigram['Cntnt_Bigram'].fillna('')\n",
    "    df_ac_pmi_dist_bigram['PMI_Bigram_SD'] = df_ac_pmi_dist_bigram['PMI_Bigram_SD'].fillna(0.0)\n",
    "    df_ac_pmi_dist_bigram = df_ac_pmi_dist_bigram.fillna(-10.0)\n",
    "\n",
    "    df_ac_pmi_dist_trigram = df_ac_pmi_dist_trigram.iloc[:, oalqd.num_clm_in_q:]\n",
    "    df_ac_pmi_dist_trigram['Cntnt_Trigram'] = df_ac_pmi_dist_trigram['Cntnt_Trigram'].fillna('')\n",
    "    df_ac_pmi_dist_trigram['PMI_Trigram_SD'] = df_ac_pmi_dist_trigram['PMI_Trigram_SD'].fillna(0.0)\n",
    "    df_ac_pmi_dist_trigram = df_ac_pmi_dist_trigram.fillna(-10.0)\n",
    "\n",
    "    if specific_count_lemmas == None:\n",
    "        df_ac_lemma = None\n",
    "    else:\n",
    "        df_ac_lemma = df_ac_lemma_buf\n",
    "    \n",
    "    df_ac_aggregate = agpl.ac_aggregate_plim(bnlqd.df_ac_pos, oalqd.num_clm_in_q + 1, \n",
    "                            df_ac_overlapping_lemma, df_ac_overlapping_synset, \n",
    "                            None, df_ac_oanc_lemma_freq, oalqd.stem_option_name_clm, stem_identifier,\n",
    "                            list(oalqd.df_ac_in_q.columns), stop_words_pos, df_ac_lemma,\n",
    "                            specific_count_lemmas, bnlpd.df_ac_pos, ovlqd.passage_name_clm_q,\n",
    "                            ovlqd.passage_sec_clm_q, ovlqd.passage_name_clm_p, ovlqd.passage_sec_clm_p,\n",
    "                            bnlpd.num_clm_in + 1, decimal_places,\n",
    "                            df_ac_overlapping_hyper, df_ac_overlapping_hypo,\n",
    "                            df_ac_bigram_pmi_distribution = df_ac_pmi_dist_bigram, \n",
    "                            df_ac_trigram_pmi_distribution = df_ac_pmi_dist_trigram)\n",
    "\n",
    "    key_dummy = r'Key_Dummy'\n",
    "    t = df_ac_aggregate.shape\n",
    "    row_lgth = t[0]\n",
    "    df_key_dummy = pd.DataFrame(np.empty((row_lgth, 1),\n",
    "                        dtype=object), df_ac_aggregate.index,\n",
    "                        [key_dummy])\n",
    "    df_key_dummy = df_key_dummy.fillna(option_identifier)\n",
    "    df_ac_aggregate[key_dummy] = df_key_dummy[key_dummy]\n",
    "\n",
    "    return df_ac_aggregate\n",
    "\n",
    "def aggregate_item_level_plim(df_ac_aggregate, task_name = 'Definition', cntnt_clm = 'Content', decimal_places = 4):\n",
    "    stem_identifier = task_name + '-Question'\n",
    "    df_ac_aggregate_item_level = agpi.ac_aggregate_item_level_plim(df_ac_aggregate,\n",
    "                            r'Key_Dummy', oalqd.stem_option_name_clm, stem_identifier, \n",
    "                            None, decimal_places, cntnt_clm)\n",
    "    return df_ac_aggregate_item_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "task_name = 'Definition'\n",
    "stop_words_pos = None\n",
    "specific_count_lemmas = [r'dk', r'nr']\n",
    "\n",
    "df_ac_aggregate = aggregate_plim(bnlqd, oalqd, ovlqd, df_ac_pmi_dist_bigram, df_ac_pmi_dist_trigram,\n",
    "        bnlpd, specific_count_lemmas, stop_words_pos, task_name)\n",
    "df_ac_aggregate.to_csv(data_dir + 'Aggregate_EN-QA-Head4-Serialized-Def-ELVA.PILOT.POST-TEST.csv', encoding= 'latin1')\n",
    "df_ac_aggregate_item_level = aggregate_item_level_plim(df_ac_aggregate, task_name)\n",
    "df_ac_aggregate_item_level.to_csv(data_dir + 'Key-Stem-Passage-Aggregate_EN-QA-Head4-Serialized-Def-ELVA.PILOT.POST-TEST.csv', encoding= 'latin1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
